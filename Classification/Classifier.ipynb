{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696289517013,"user":{"displayName":"Mahdi Moeini","userId":"03671813669356560168"},"user_tz":-210},"id":"za0kvkt7u2Z5","outputId":"78ba6e7e-7a2c-4096-e595-beca84ab98ba"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mahdi146/jupyter2/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n","  from pandas import MultiIndex, Int64Index\n"]}],"source":["import sys\n","import mne\n","import scipy.io as sp\n","import numpy as np\n","import random\n","import pandas as pd\n","import multiprocessing as mp\n","import concurrent.futures\n","from mne.decoding import CSP\n","import pymrmr\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier as RF\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import logging\n","from scipy.io import loadmat\n","from scipy.signal import hamming\n","from scipy.signal import hann\n","from scipy.signal import blackman\n","from scipy.signal import kaiser\n","from scipy.signal import gaussian\n","from sklearn.decomposition import FastICA\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","import lightgbm as lgb\n","from catboost import CatBoostClassifier"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","\n","# Set display options for NumPy\n","np.set_printoptions(threshold=np.inf)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["WINDOW_TIME_LENGTH = 4\n","SAMPLING_RATE = 250\n","TR_SLIDING_WINDOW_TIME = 2\n","WINDOW_SAMPLE_LENGTH = WINDOW_TIME_LENGTH*SAMPLING_RATE\n","NUMBER_OF_CHANNELS = 64\n","SLIDING_TIME = 4 \n","SLIDING_POINTS = SLIDING_TIME*SAMPLING_RATE\n","TR_SLIDING_POINTS = TR_SLIDING_WINDOW_TIME*SAMPLING_RATE\n","beta = 1.5\n","\n","num_channels = 64\n","epoch_length = 1000\n","sampling_freq = 250\n","number_of_runs = 10\n","# number_of_splits = 10\n","number_of_components = 10\n","number_of_selected_features = 10\n","number_of_processes = 10\n","number_of_bands = 9\n","# rf = pd.DataFrame()\n","column_names = ['participant', 'class1', 'class2','running_time','test_acc','train_acc','test_size','train_size','train_block','test_block']\n","# rf = rf.reindex(columns=column_names)\n","\n","trial_order=[['Tongue','Feet','Mis','Hand'],\n","            ['Feet','Mis','Hand','Tongue'],\n","            ['Hand','Feet','Tongue','Mis'],\n","            ['Tongue','Mis','Hand','Feet'],\n","            ['Mis','Feet','Hand','Tongue'],\n","            ['Feet','Hand','Tongue','Mis'],\n","            ['Hand','Tongue','Mis','Feet'],\n","            ['Tongue','Feet','Mis','Hand'],\n","            ['Mis','Tongue','Hand','Feet']]\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_task_rest_times(b_num):\n","    if b_num == 0:\n","        task_time = [[12, 16, 20, 8],\n","                    [16, 12, 20, 8],\n","                    [20, 16, 8, 12],\n","                    [20, 12, 8, 16]]\n","        \n","        rest_time = [[20, 8, 16, 12],\n","                    [16, 20, 8, 12],\n","                    [12, 20, 16, 8],\n","                    [20, 12, 8, 16]]\n","        \n","    elif b_num == 1:\n","        task_time = [[12, 8, 20, 16],\n","                    [16, 20, 8, 12],\n","                    [8, 20, 16, 12],\n","                    [8, 12, 20, 16]]\n","        \n","        rest_time = [[16, 12, 8, 20],\n","                    [8, 20, 12, 16],\n","                    [20, 16, 8, 12],\n","                    [12, 16, 20, 8]]\n","        \n","    elif b_num == 2:\n","        task_time = [[16, 8, 12, 20],\n","                    [20, 16, 12, 8],\n","                    [12, 20, 8, 16],\n","                    [8, 12, 16, 20]]\n","        \n","        rest_time = [[8, 20, 16, 12],\n","                    [12, 8, 20, 16],\n","                    [16, 12, 20, 8],\n","                    [8, 12, 20, 16]]\n","        \n","    elif b_num == 3:\n","        task_time = [[12, 16, 20, 8],\n","                    [16, 12, 20, 8],\n","                    [20, 16, 8, 12],\n","                    [20, 12, 8, 16]]\n","        \n","        rest_time = [[20, 8, 16, 12],\n","                    [16, 20, 8, 12],\n","                    [12, 20, 16, 8],\n","                    [20, 12, 8, 16]]\n","        \n","    elif b_num == 4:\n","        task_time = [[16, 8, 20, 12],\n","                    [12, 16, 8, 20],\n","                    [20, 8, 12, 16],\n","                    [8, 20, 12, 16]]\n","        \n","        rest_time = [[8, 12, 16, 20],\n","                    [16, 20, 12, 8],\n","                    [12, 16, 8, 20],\n","                    [20, 8, 12, 16]]\n","        \n","    elif b_num == 5:\n","        task_time = [[16, 12, 8, 20],\n","                    [20, 16, 12, 8],\n","                    [8, 16, 20, 12],\n","                    [12, 8, 16, 20]]\n","\n","        rest_time = [[12, 8, 16, 20],\n","                    [16, 8, 20, 12],\n","                    [20, 12, 16, 8],\n","                    [8, 16, 12, 20]]\n","        \n","    elif b_num == 6:\n","        task_time = [[16, 8, 12, 20],\n","                    [20, 8, 16, 12],\n","                    [8, 16, 12, 20],\n","                    [16, 20, 12, 8]]\n","\n","        rest_time = [[16, 8, 12, 20],\n","                    [12, 20, 8, 16],\n","                    [20, 16, 12, 8],\n","                    [8, 16, 20, 12]]     \n","    elif b_num ==7:\n","        task_time = [[12, 8, 20, 16],\n","                    [16, 20, 8, 12],\n","                    [8, 20, 16, 12],\n","                    [8, 12, 20, 16]]   \n","               \n","        rest_time = [[16, 12, 8, 20],\n","                    [8, 20, 12, 16],\n","                    [20, 16, 8, 12],\n","                    [12, 16, 20, 8]]  \n","    \n","    elif b_num == 8:\n","        task_time = [[16, 8, 12, 20],\n","                    [20, 16, 12, 8],\n","                    [12, 20, 8, 16],\n","                    [8, 12, 16, 20]]\n","        \n","        rest_time = [[8, 20, 16, 12],\n","                    [12, 8, 20, 16],\n","                    [16, 12, 20, 8],\n","                    [8, 12, 20, 16]]\n","        \n","    else:\n","        print(\"Error in block number\")\n","\n","    return task_time,rest_time\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def trial_times_genertor(task_times,rest_times):\n","    block_times = [item for pair in zip(task_times, rest_times) for item in pair]\n","    return block_times\n","    "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def calc_csp(x_train, y_train, x_test):\n","    csp = CSP(number_of_components)\n","    csp_fit = csp.fit(x_train, y_train)\n","    train_feat = csp_fit.transform(x_train)\n","    test_feat = csp_fit.transform(x_test)\n","    return train_feat, test_feat"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def class_extractor(number_of_epochs, class_1, class_2, data, labels):\n","    size = sum(labels[:,0] == class_1) + sum(labels[:,0] == class_2)\n","    Final_labels = np.zeros((size,1)).astype(int)\n","    dataset = np.zeros((size,num_channels, epoch_length))\n","    index = 0\n","    for i in range(number_of_epochs):\n","        if labels[i,0] == class_1 or labels[i,0] == class_2:\n","            dataset[index,:,:] = data[i,:,:]\n","            Final_labels[index,0] = labels[i,0]\n","            index = index + 1\n","        else:\n","            continue\n","            \n","    return dataset, Final_labels"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def feature_extractor(dataset, labels, number_of_bands, test_data):\n","\n","    low_cutoff = 0\n","    \n","    for b in range(number_of_bands):\n","        logging.getLogger('mne').setLevel(logging.WARNING)\n","        low_cutoff += 4\n","        data = dataset.copy()\n","        data_test = test_data.copy()\n","        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False, n_jobs = 4)\n","        filtered_data_test = mne.filter.filter_data(test_data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False, n_jobs = 4)\n","        [train_feats, test_feats] = calc_csp(filtered_data, labels[:,0], filtered_data_test)\n","        if b == 0:\n","            train_features = train_feats\n","            test_features = test_feats\n","        else:\n","            train_features = np.concatenate((train_features, train_feats), axis = 1)\n","            test_features = np.concatenate((test_features, test_feats), axis = 1)\n","    \n","    return train_features, test_features"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def feature_selector(train_features, labels, number_of_selected_features):\n","    X = pd.DataFrame(train_features)\n","    y = pd.DataFrame(labels)\n","    K = number_of_selected_features\n","    \n","    df = pd.concat([y,X], axis = 1)\n","    df.columns = df.columns.astype(str)\n","        \n","    selected_features = list(map(int, pymrmr.mRMR(df, 'MID', K)))\n","    return selected_features"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def data_reader(path,p_num,block_list):\n","    data_dict = {}\n","    for b_num in block_list:\n","        print(b_num)\n","        mat = loadmat(path+'P'+str(p_num)+'B'+str(b_num)+'.mat', chars_as_strings=True, mat_dtype=True, squeeze_me=True, struct_as_record=False, verify_compressed_data_integrity=False, variable_names=None)\n","        df = pd.DataFrame(mat['Data'])\n","        # ddf = dd.from_pandas(df, npartitions=10)\n","        data_dict[b_num] = df\n","    return data_dict\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def extra_samples_counter(df,class_1,class_2):\n","    x=0\n","    i=0\n","    sampleList = []\n","    while i<len(df):\n","        if (df.iloc[i,64]==class_1):\n","            x+=1\n","        else:\n","            i-=1\n","            sampleList.append(x)\n","            x=0\n","            class_1,class_2 = class_2,class_1\n","        i+=1\n","    sampleList.append(x)\n","    print(sampleList)\n","    "]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["def extra_samples_block_counter(df,trial_order,b_num):\n","\n","    df.drop(df[df.iloc[:,64].isin(['Begin', 'End'])].index, inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","    print('hi')\n","    \n","    df['group'] = (df.iloc[:,64] != df.iloc[:,64].shift(1)).cumsum()\n","    # group_counts_Tongue = df[df.iloc[:,64] == 'Tongue'].groupby('group').size()\n","    # group_counts_Feet = df[df.iloc[:,64] == 'Feet'].groupby('group').size()\n","    # group_counts_Hand = df[df.iloc[:,64] == 'Hand'].groupby('group').size()\n","    # group_counts_Mis = df[df.iloc[:,64] == 'Mis'].groupby('group').size()\n","    # group_counts_Rest = df[df.iloc[:,64] == 'Rest'].groupby('group').size()\n","\n","    \n","    group_counts_Rest = df[df.iloc[:,64] == 'Rest'].groupby('group').size()\n","    with open('sampleList.txt', 'a') as file:\n","        file.write(f'block {b_num+1} '+'\\n')\n","        for j in range (len(trial_order)):\n","            print(trial_order[j])\n","            trial_num = j\n","            task_times,rest_times = get_task_rest_times(b_num)\n","            trial_times = trial_times_genertor(task_times[trial_num],rest_times[trial_num])\n","            trial_samples = [item*SAMPLING_RATE for item in trial_times]\n","            group_counts_task = df[df.iloc[:,64] == trial_order[j]].groupby('group').size()\n","            sampleList = []\n","            for i in range(4):\n","                task = group_counts_task.iloc[i]\n","                rest = group_counts_Rest.iloc[4*j+i]\n","                sampleList.append(task)\n","                sampleList.append(rest)\n","            extra_samples = [x-y for x,y in zip(sampleList,trial_samples)]\n","            file.write(', '.join(map(str, extra_samples)) + f' trial={trial_order[j]} '+'\\n')\n","            print(sampleList)\n","        file.write('\\n\\n')\n","\n","\n","    # print(group_counts_Tongue)\n","    # print(group_counts_Feet)\n","    # print(group_counts_Hand)\n","    # print(group_counts_Mis)\n","    # print(group_counts_Rest)\n","\n","    # print(group_counts_b.index[0])\n","    # print(group_counts_b.iloc[0])\n","    # print(group_counts)\n","\n","\n","    # for j in range(len(trial_order)):\n","    #     print(j)\n","    #     class_2 = 'Rest'\n","    #     class_1 = trial_order[j]\n","    #     sampleList = []\n","    #     x=0\n","    #     i=0\n","\n","\n","    #     while i<len(df):\n","    #         print(i)\n","    #         if (df.iloc[i,64]!=class_1):\n","    #             x+=1\n","    #         else:\n","    #             i-=1\n","    #             sampleList.append(x)\n","    #             x=0\n","    #             class_1,class_2 = class_2,class_1\n","    #         i+=1\n","    #     sampleList.append(x)\n","    #     df.drop(df.index[0:sum(sampleList)], inplace=True)\n","    #     df.reset_index(drop=True, inplace=True)\n","    #     print(sampleList)\n","        # with open('sampleList.txt', 'w') as file:\n","        #     # for item in sampleList:\n","        #     file.write(f\"{sampleList}\\n\")\n","    "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","def data_cleaner(df,class_1,class_2,tasks_time):\n","    # extra_samples_counter(df,class_1,class_2)\n","    # sys.exit() \n","    class_x = class_1\n","    class_y = class_2\n","    new_df = pd.DataFrame()\n","    trial_df = df.copy() \n","    print(tasks_time)\n","    for i in range(len(tasks_time)):\n","        sample_point = tasks_time[i]*SAMPLING_RATE\n","        if(trial_df.iloc[sample_point+1,64] == class_x ):\n","            if(i==len(tasks_time)-1):\n","                temp_df = trial_df.iloc[:sample_point,:]\n","                new_df = pd.concat([new_df, temp_df], axis=0)\n","                new_df.reset_index(drop=True, inplace=True)\n","            else:    \n","                temp_df = trial_df.iloc[:sample_point,:]\n","                next_task_idx = trial_df[trial_df.iloc[:, 64] == class_y].index\n","                trial_df.drop(trial_df.index[0:next_task_idx[0]], inplace=True)\n","                trial_df.reset_index(drop=True, inplace=True)\n","                new_df = pd.concat([new_df, temp_df], axis=0)\n","                new_df.reset_index(drop=True, inplace=True)\n","                class_x,class_y = class_y,class_x\n","\n","    return new_df"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def class_seperator(cleaned_df,class_1,class_2):\n","    # df = cleaned_df.sort_values(by=cleaned_df.columns[64]).reset_index(drop=True)\n","    # print(seperated_df.head(14003))\n","    # print(cleaned_df.head(5003))\n","\n","    df = cleaned_df\n","    sorting_order = {class_1: 0, class_2: 1}\n","\n","    df['sorting_order'] = df.iloc[:, 64].map(sorting_order)\n","    df.sort_values(by=['sorting_order', df.columns[64]], inplace=True)\n","    df.drop('sorting_order', axis=1, inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    return df"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def shuffler(dataset,labels):\n","    print(dataset.shape)\n","    print(labels.shape)\n","    np.random.seed(42)\n","    indices = np.random.permutation(len(dataset))\n","    shuffled_dataset = dataset[indices]\n","    shuffled_labels = labels[indices]\n","    return shuffled_dataset,shuffled_labels\n","    "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def data_label_attacher(cleaned_df,class_1,class_2,random_flag,class_seperator_flag):\n","    \n","    #Initialization\n","    if class_seperator_flag:\n","        seperated_class_df = class_seperator(cleaned_df,class_1,class_2)\n","        new_df_ = seperated_class_df.copy()\n","        new_df_.drop(seperated_class_df.columns[-1], axis=1, inplace=True)\n","        X = new_df_.to_numpy()\n","        X = np.transpose(X)\n","        number_of_epochs = int((int(len(new_df_))-WINDOW_SAMPLE_LENGTH)/TR_SLIDING_POINTS)\n","        print(number_of_epochs)\n","    else :  \n","        new_df_ = cleaned_df.copy()\n","        new_df_.drop(cleaned_df.columns[-1], axis=1, inplace=True)\n","        X = new_df_.to_numpy()\n","        X = np.transpose(X)\n","        number_of_epochs = int(len(new_df_)/WINDOW_SAMPLE_LENGTH)\n","\n","    dataset = np.zeros((number_of_epochs,NUMBER_OF_CHANNELS,WINDOW_SAMPLE_LENGTH))\n","    labels = np.zeros((number_of_epochs,1)).astype(int)\n","\n","    if class_seperator_flag:\n","        i = 0  \n","        startIdx = i * WINDOW_SAMPLE_LENGTH\n","        endIdx = (i+1) * WINDOW_SAMPLE_LENGTH \n","        while(endIdx<=int(len(new_df_))/2):\n","            slice_X = X[:, startIdx:endIdx]\n","            kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","            slice_X *= kaiser_window\n","            dataset[i, :, :] = slice_X\n","            labels[i,0] = 0\n","            # if (seperated_class_df.iloc[startIdx, 64] == class_1):\n","            #     labels[i,0] = 0\n","            # elif(seperated_class_df.iloc[startIdx, 64] == class_2):\n","            #     labels[i,0] = 1\n","            # else:\n","            #     labels[i,0] = 2\n","            startIdx+=TR_SLIDING_POINTS\n","            endIdx+=TR_SLIDING_POINTS\n","            i+=1\n","        # print(int(len(new_df_))/2,\"len\")    \n","        # print(endIdx,\"endIdx\")    \n","        # print(seperated_class_df.iloc[endIdx-2:endIdx+2,64])\n","       \n","        j = i\n","        \n","        startIdx = endIdx-TR_SLIDING_POINTS\n","        endIdx = startIdx+WINDOW_SAMPLE_LENGTH\n","        print(j, \"j is this\")\n","        while(endIdx<=int(len(new_df_))):\n","            slice_X = X[:, startIdx:endIdx]\n","            kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","            slice_X *= kaiser_window\n","            dataset[j, :, :] = slice_X\n","            labels[j,0] = 1\n","            # if (cleaned_df.iloc[startIdx, 64] == class_1):\n","            #     labels[j,0] = 0\n","            # elif(cleaned_df.iloc[startIdx, 64] == class_2):\n","            #     labels[j,0] = 1\n","            # else:\n","            #     labels[j,0] = 2\n","            startIdx+=TR_SLIDING_POINTS\n","            endIdx+=TR_SLIDING_POINTS\n","            j+=1\n","        print(j, \"j is this\")\n","        # dataset,labels = shuffler(dataset,labels)\n","\n","    else:\n","        i = 0  \n","        start_idx = i * WINDOW_SAMPLE_LENGTH\n","        end_idx = (i+1) * WINDOW_SAMPLE_LENGTH \n","        while (end_idx<=int(len(new_df_))):\n","            slice_X = X[:, start_idx:end_idx]\n","            kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","            slice_X *= kaiser_window\n","            dataset[i, :, :] = slice_X\n","            if (cleaned_df.iloc[start_idx, 64] == class_1):\n","                labels[i,0] = 0\n","            elif(cleaned_df.iloc[start_idx, 64] == class_2):\n","                labels[i,0] = 1\n","            else:\n","                labels[i,0] = 2\n","            start_idx+=SLIDING_POINTS\n","            end_idx+=SLIDING_POINTS\n","            i+=1\n","        # dataset,labels = shuffler(dataset,labels)\n","\n","\n","\n","\n","\n","\n","\n","    #For training and test purpose\n","    # if random_flag:\n","    #     randomlist = random.sample(range(number_of_epochs), number_of_epochs)\n","    # else:\n","    #     randomlist = list(range(number_of_epochs))\n","    #Labeling the data\n","\n","\n","\n","    # for i in range(number_of_epochs):\n","    #     start_idx = randomlist[i] * WINDOW_SAMPLE_LENGTH + SLIDING_POINTS\n","    #     end_idx = (randomlist[i] + 1) * WINDOW_SAMPLE_LENGTH\n","    #     slice_X = X[:, start_idx:end_idx]\n","\n","    #     # hamming_window = hamming(WINDOW_SAMPLE_LENGTH)\n","    #     # slice_X *= hamming_window\n","\n","    #     # hanning_window = hann(WINDOW_SAMPLE_LENGTH)\n","    #     # slice_X *= hanning_window\n","\n","    #     # blackman_window = blackman(WINDOW_SAMPLE_LENGTH)\n","    #     # slice_X *= blackman_window\n","\n","    #     # kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,0.5)\n","    #     # slice_X *= kaiser_window\n","\n","    #     # gaussian_window = gaussian(WINDOW_SAMPLE_LENGTH,0.5)\n","    #     # slice_X *= gaussian_window\n","\n","\n","    #     dataset[i, :, :] = slice_X\n","    #     if (cleaned_df.iloc[randomlist[i] * WINDOW_SAMPLE_LENGTH, 64] == class_1):\n","    #         labels[i,0] = 0\n","    #     elif(cleaned_df.iloc[randomlist[i] * WINDOW_SAMPLE_LENGTH, 64] == class_2):\n","    #         labels[i,0] = 1\n","    #     else:\n","    #         labels[i,0] = 2\n","\n","    return dataset,labels\n","\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def trial_cutter(data, class_1):\n","    df = data.copy()\n","    Begin_trigger = \"Begin\" + \"_\" + class_1\n","    End_trigger = \"End\" + \"_\" + class_1\n","    Begin_idx = df[df.iloc[:, 64] == Begin_trigger].index\n","    End_idx = df[df.iloc[:, 64] == End_trigger].index\n","    trial_df = df.iloc[Begin_idx[0]+1:End_idx[0],:]\n","    trial_df.reset_index(drop=True, inplace=True)\n","    trial_df.head()\n","    return trial_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def Begin_End_trigger_modifier(data):\n","    df = data.copy()\n","    Begin_indexes = df[df.iloc[:, 64] == 'Begin'].index\n","    End_indexes = df[df.iloc[:, 64] == 'End'].index\n","    if(len(Begin_indexes)==len(End_indexes)):\n","        for i in range(len(Begin_indexes)):\n","            index = Begin_indexes[i]+1\n","            val = df.iloc[index,64]\n","            df.iloc[Begin_indexes[i],64] = \"Begin\" + \"_\" + str(val)\n","            df.iloc[End_indexes[i],64]   =  \"End\" + \"_\" + str(val)\n","    else:\n","        print(\"Trigger seinding Exception\")\n","    \n","    return df"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def preprocessor(data_,class_1,class_2,tasks_time,set_type,class_seperator_flag):\n","    CLASS_1 = class_1\n","    CLASS_2 = class_2\n","    df = data_.copy()\n","    modified_df = Begin_End_trigger_modifier(df)\n","    trial_df = trial_cutter(modified_df,CLASS_1)\n","    print(trial_df.shape,\"trial_df\")\n","    cleaned_df = data_cleaner(trial_df,CLASS_1,CLASS_2,tasks_time)\n","    print(cleaned_df.shape,\"cleaned_df\")\n","\n","    if set_type ==\"TRAIN\":\n","        random_flag = True\n","    elif set_type ==\"TEST\":\n","        random_flag = False\n","    else:\n","        print(\"Error in set type\")\n","\n","  \n","    final_data, final_labels = data_label_attacher(cleaned_df,CLASS_1,CLASS_2,random_flag,class_seperator_flag)\n","    print(final_data.shape,\"final_data shape\")\n","    print(final_labels.shape,\"final_labels shape\")\n","    \n","    return final_data,final_labels"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def trials_set_builder(data_dict,blocks_set,set_label,class_1,class_2,class_seperator_flag):\n","    counter = 0\n","\n","    for b_num in blocks_set:\n","        trial_num = trial_order[b_num].index(class_1)\n","        task_times,rest_times = get_task_rest_times(b_num)\n","        print(task_times[trial_num],rest_times[trial_num])\n","        trial_times = trial_times_genertor(task_times[trial_num],rest_times[trial_num])\n","        print(trial_times)\n","        data = data_dict[b_num]\n","        df = data.copy()\n","        # last_column = df.pop(df.columns[-1])\n","        # df.drop(df.columns[-1], axis=1, inplace=True)\n","        # eeg_data = df.to_numpy().T  # Transpose to have channels in columns\n","\n","        # channel_names = [f'Ch{i+1}' for i in range(63)]\n","\n","        # # Create MNE-Python RawArray object\n","        # info = mne.create_info(ch_names=channel_names, sfreq=sampling_freq, ch_types='eeg')\n","        # raw = mne.io.RawArray(eeg_data, info)\n","\n","        # # Apply ICA\n","        # ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n","        # ica.fit(raw)\n","        # ica_components = ica.get_components()\n","\n","        # # Convert the ICA components to a DataFrame\n","        # df2 = pd.DataFrame(data=ica_components.T, columns=channel_names)\n","        # df2 = df2.assign(LastColumn=last_column)\n","        # # df = data.copy(deep=False)\n","        dataset,labels = preprocessor(df,class_1,class_2,trial_times,set_label,class_seperator_flag)\n","        # print(dataset.shape)\n","\n","        if counter == 0 :\n","            final_data = dataset\n","            final_labels = labels\n","            print(\"Before concatenation - final_data shape:\", final_data.shape, \"dataset shape:\", dataset.shape)\n","        else:\n","            final_data = np.vstack((final_data, dataset))\n","            final_labels = np.vstack((final_labels, labels))\n","            print(\"After concatenation - final_data shape:\", final_data.shape, \"final_labels shape:\", final_labels.shape)\n","\n","        counter+=1 \n","    return final_data,final_labels"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["# PATH = '../../Participants/P1/'\n","# P_NUM = 1\n","# B_NUM = 1\n","# CLASS_1 = \"Feet\"\n","# CLASS_2 = \"Rest\"\n","# data_tr_ = data_reader(PATH+'P'+str(P_NUM)+'B'+str(B_NUM)+'.mat')\n","# data_tr2_ = data_reader(PATH+'P'+str(P_NUM)+'B'+str(4)+'.mat')\n","# data_te_ = data_reader(PATH+'P'+str(P_NUM)+'B'+str(6)+'.mat')\n","\n","\n","\n","\n","\n","# for i in range(number_of_epochs):\n","#     data[i,:,:] = X[:, randomlist[i]*epoch_length:(randomlist[i] + 1)*epoch_length]\n","#     if (df['condition'][randomlist[i]*epoch_length] == 'Left'):\n","#         labels[i,0] = 0\n","#     elif(df['condition'][randomlist[i]*epoch_length] == 'Right'):\n","#         labels[i,0] = 1\n","#     elif(df['condition'][randomlist[i]*epoch_length] == 'Feet'):\n","#         labels[i,0] = 2\n","#     elif(df['condition'][randomlist[i]*epoch_length] == 'Tongue'):\n","#         labels[i,0] = 3\n","#     elif(df['condition'][randomlist[i]*epoch_length] == 'Mis'):\n","#         labels[i,0] = 4\n","#     elif(df['condition'][randomlist[i]*epoch_length] == 'Si'):\n","#         labels[i,0] = 5\n","#     else:\n","#         labels[i,0] = 6\n","\n","\n","\n","# preprocessor(data_tr,data_te)\n","\n","# X_tr_raw,X_te_raw,y_tr_raw,y_te_raw,number_of_epochs_tr,number_of_epochs_te = preprocessor(X_train,X_test,data1)\n","# [X_tr, y_tr] = class_extraction(number_of_epochs_tr, class_1, class_2, X_tr_raw, y_tr_raw)\n","# [X_te, y_te] = class_extraction(number_of_epochs_te, class_1, class_2, X_te_raw, y_te_raw) \n","# print(X_te.shape,\"X_te.shape\")\n"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]},{"ename":"MemoryError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m blcok_list \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m p_num \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m data_dict \u001b[39m=\u001b[39m data_reader(\u001b[39m'\u001b[39;49m\u001b[39m../../Participants/P1/\u001b[39;49m\u001b[39m'\u001b[39;49m,p_num,blcok_list)\n","\u001b[1;32m/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m b_num \u001b[39min\u001b[39;00m block_list:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(b_num)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     mat \u001b[39m=\u001b[39m loadmat(path\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mP\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(p_num)\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(b_num)\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.mat\u001b[39;49m\u001b[39m'\u001b[39;49m, chars_as_strings\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, mat_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, squeeze_me\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, struct_as_record\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, verify_compressed_data_integrity\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, variable_names\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mat[\u001b[39m'\u001b[39m\u001b[39mData\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     ddf \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mfrom_pandas(df, npartitions\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 227\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39;49mget_variables(variable_names)\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m mdict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     mdict\u001b[39m.\u001b[39mupdate(matfile_dict)\n","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio5.py:312\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    310\u001b[0m mdict[\u001b[39m'\u001b[39m\u001b[39m__globals__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m    311\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_of_stream():\n\u001b[0;32m--> 312\u001b[0m     hdr, next_position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_var_header()\n\u001b[1;32m    313\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m hdr\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m hdr\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m mdict:\n","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio5.py:266\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_matrix_reader\u001b[39m.\u001b[39mset_stream(stream)\n\u001b[1;32m    265\u001b[0m     check_stream_limit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_compressed_data_integrity\n\u001b[0;32m--> 266\u001b[0m     mdtype, byte_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_matrix_reader\u001b[39m.\u001b[39;49mread_full_tag()\n\u001b[1;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     check_stream_limit \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m_mio5_utils.pyx:544\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_full_tag\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_mio5_utils.pyx:552\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.cread_full_tag\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_streams.pyx:147\u001b[0m, in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream.read_into\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_streams.pyx:134\u001b[0m, in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream._fill_buffer\u001b[0;34m()\u001b[0m\n","\u001b[0;31mMemoryError\u001b[0m: "]}],"source":["blcok_list = [0,1,3,4,5,6,7,8]\n","p_num = 1\n","data_dict = data_reader('../../Participants/P1/',p_num,blcok_list)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n"]}],"source":["blcok_list = [0,1,2,3,4,5,6]\n","p_num = 4\n","data_dict_3 = data_reader(f'../../Participants/P{p_num}/',p_num,blcok_list)"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[16, 12, 20, 8] [16, 20, 8, 12]\n","[16, 16, 12, 20, 20, 8, 8, 12]\n","(28473, 65) trial_df\n","[4078, 4078, 3089, 5079, 5078, 2032, 2031, 3008]\n","[16, 16, 12, 20, 20, 8, 8, 12]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","Before concatenation - final_data shape: (28, 64, 1000) dataset shape: (28, 64, 1000)\n","[12, 8, 20, 16] [16, 12, 8, 20]\n","[12, 16, 8, 12, 20, 8, 16, 20]\n","(28491, 65) trial_df\n","[3089, 4081, 2030, 3090, 5077, 2034, 4082, 5008]\n","[12, 16, 8, 12, 20, 8, 16, 20]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (56, 64, 1000) final_labels shape: (56, 1)\n","[20, 16, 12, 8] [12, 8, 20, 16]\n","[20, 12, 16, 8, 12, 20, 8, 16]\n","(28486, 65) trial_df\n","[5078, 3088, 4078, 2030, 3091, 5082, 2032, 4007]\n","[20, 12, 16, 8, 12, 20, 8, 16]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (84, 64, 1000) final_labels shape: (84, 1)\n","[20, 12, 8, 16] [20, 12, 8, 16]\n","[20, 20, 12, 12, 8, 8, 16, 16]\n","(28551, 65) trial_df\n","[5077, 5111, 3089, 3119, 2027, 2043, 4078, 4007]\n","[20, 20, 12, 12, 8, 8, 16, 16]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (112, 64, 1000) final_labels shape: (112, 1)\n","[12, 16, 8, 20] [16, 20, 12, 8]\n","[12, 16, 16, 20, 8, 12, 20, 8]\n","(28691, 65) trial_df\n","[3130, 4082, 4088, 5132, 2029, 3144, 5079, 2007]\n","[12, 16, 16, 20, 8, 12, 20, 8]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (140, 64, 1000) final_labels shape: (140, 1)\n","[16, 12, 8, 20] [12, 8, 16, 20]\n","[16, 12, 12, 8, 8, 16, 20, 20]\n","(28586, 65) trial_df\n","[4096, 3106, 3112, 2041, 2041, 4089, 5094, 5007]\n","[16, 12, 12, 8, 8, 16, 20, 20]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","Before concatenation - final_data shape: (28, 64, 1000) dataset shape: (28, 64, 1000)\n","[16, 20, 12, 8] [8, 16, 20, 12]\n","[16, 8, 20, 16, 12, 20, 8, 12]\n","(28485, 65) trial_df\n","[4090, 2044, 5089, 4087, 3093, 5037, 2039, 3006]\n","[16, 8, 20, 16, 12, 20, 8, 12]\n","(28000, 65) cleaned_df\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (56, 64, 1000) final_labels shape: (56, 1)\n","(140, 64, 1000) (140, 1) train shape\n","(56, 64, 1000) (56, 1) test shape\n"]},{"name":"stderr","output_type":"stream","text":["3782.88s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n","3783.05s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n","3783.21s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n","3783.38s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n","0.62s - Expected: /home/mahdi146/jupyter2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd_attach_to_process/attach_linux_amd64.so to exist.\n","0.52s - Expected: /home/mahdi146/jupyter2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd_attach_to_process/attach_linux_amd64.so to exist.\n","0.55s - Expected: /home/mahdi146/jupyter2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd_attach_to_process/attach_linux_amd64.so to exist.\n","0.57s - Expected: /home/mahdi146/jupyter2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd_attach_to_process/attach_linux_amd64.so to exist.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n"," *** This program and the respective minimum Redundancy Maximum Relevance (mRMR) \n","     algorithm were developed by Hanchuan Peng <hanchuan.peng@gmail.com>for\n","     the paper \n","     \"Feature selection based on mutual information: criteria of \n","      max-dependency, max-relevance, and min-redundancy,\"\n","      Hanchuan Peng, Fuhui Long, and Chris Ding, \n","      IEEE Transactions on Pattern Analysis and Machine Intelligence,\n","      Vol. 27, No. 8, pp.1226-1238, 2005.\n","\n","\n","*** MaxRel features ***\n","Order \t Fea \t Name \t Score\n","1 \t 31 \t 30 \t 0.470\n","2 \t 34 \t 33 \t 0.414\n","3 \t 22 \t 21 \t 0.387\n","4 \t 44 \t 43 \t 0.387\n","5 \t 55 \t 54 \t 0.376\n","6 \t 14 \t 13 \t 0.368\n","7 \t 13 \t 12 \t 0.346\n","8 \t 21 \t 20 \t 0.345\n","9 \t 11 \t 10 \t 0.342\n","10 \t 69 \t 68 \t 0.331\n","\n","*** mRMR features *** \n","Order \t Fea \t Name \t Score\n","1 \t 31 \t 30 \t 0.470\n","2 \t 58 \t 57 \t 0.120\n","3 \t 10 \t 9 \t 0.110\n","4 \t 14 \t 13 \t 0.150\n","5 \t 69 \t 68 \t 0.143\n","6 \t 39 \t 38 \t 0.115\n","7 \t 22 \t 21 \t 0.126\n","8 \t 13 \t 12 \t 0.118\n","9 \t 17 \t 16 \t 0.102\n","10 \t 34 \t 33 \t 0.117\n","[1.0] train\n","[0.8928571428571429] test\n"]}],"source":["\n","\n","PATH = '../../Participants/P3/'\n","class_1 = 'Feet'\n","class_2 = 'Rest'\n","b_num = 0\n","p_num = 3\n","train_blocks_set = [0,1,2,3,4]\n","test_blocks_set = [5,6]\n","\n","X_tr, Y_tr = trials_set_builder(data_dict_3,train_blocks_set,'TRAIN',class_1,class_2,False)\n","X_te, Y_te = trials_set_builder(data_dict_3,test_blocks_set,'TEST',class_1,class_2,False)\n","\n","print(X_tr.shape,Y_tr.shape,\"train shape\")\n","print(X_te.shape,Y_te.shape,\"test shape\")\n","\n","[train_features, test_features] = feature_extractor(X_tr, Y_tr, number_of_bands, X_te)\n","selected_features = feature_selector(train_features, Y_tr, number_of_selected_features)\n","\n","train_acc_list = []\n","test_acc_list = []\n","\n","clf = XGBClassifier()\n","for r in range(1):\n","    clf.fit(train_features[:, selected_features], Y_tr[:,0])\n","\n","    y_pr_te = clf.predict(test_features[:, selected_features])\n","    y_pr_tr = clf.predict(train_features[:,selected_features])\n","\n","    accuracy_te = accuracy_score(Y_te, y_pr_te)\n","    test_acc_list.append(accuracy_te)\n","\n","    accuracy_tr = accuracy_score(Y_tr,y_pr_tr)\n","    train_acc_list.append(accuracy_tr)\n","\n","print(train_acc_list,\"train\")\n","print(test_acc_list,\"test\")\n","\n","\n","    \n","\n","\n","\n","# block_order_tr = ['Tongue','Feet','Mis','Hand']\n","# block_order_tr2 = ['Tongue','Mis','Hand','Feet']\n","# block_order_te = ['Feet','Hand','Tongue','Mis']\n","# CLASS_1 = \"Hand\"\n","# CLASS_2 = \"Rest\"\n","# tasks_time_tr = [16,16,12,20,20,8,8,12]\n","# tasks_time_tr2 = [20,20,12,12,8,8,16,16]\n","# tasks_time_te = [16,12,12,8,8,16,20,20]\n","\n","# df_tr = data_tr_.copy()\n","# df_tr2 = data_tr2_.copy()\n","# df_te = data_te_.copy()\n","# data_tr,labels_tr = preprocessor(df_tr,CLASS_1,CLASS_2,tasks_time_tr,\"TRAIN\")\n","# data_tr2,labels_tr2 = preprocessor(df_tr2,CLASS_1,CLASS_2,tasks_time_tr2,\"TRAIN\")\n","# data_te,labels_te = preprocessor(df_te,CLASS_1,CLASS_2,tasks_time_te,\"TEST\")\n","# data_tr = np.vstack((data_tr, data_tr2))\n","# labels_tr = np.vstack((labels_tr, labels_tr2))\n","# print(data_tr.shape)\n","# print(labels_tr.shape)\n","# print(data_te.shape)\n","# print(labels_te.shape)\n","\n","\n","\n","\n","\n","# print(data_tr.shape,labels_tr.shape)\n","# print(data_te.shape,labels_te.shape)\n","# print(labels_te)\n","# print(indexes)\n","# print(Begin_indexes)\n","# print(End_indexes)\n","# print(df.iloc[1,64])\n","\n","\n","    \n","\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39miloc[:, \u001b[39m64\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEnd_Tongue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mindex\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(idx[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgraham.computecanada.ca/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Classifier.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m CLASS_1 \u001b[39m=\u001b[39m block_order[\u001b[39m0\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["idx = df[df.iloc[:, 64] == 'End_Tongue'].index\n","print(idx[0])\n","\n","CLASS_1 = block_order[0]\n","CLASS_2 = 'Rest'\n","Begin_trigger = \"Begin\" + \"_\" + CLASS_1\n","End_trigger = \"End\" + \"_\" + CLASS_1\n","\n","Begin_idx = df[df.iloc[:, 64] == Begin_trigger].index\n","End_idx = df[df.iloc[:, 64] == End_trigger].index\n","print(Begin_idx[0],End_idx[0])\n","\n","trial_df = df.iloc[Begin_idx[0]+1:End_idx[0],:]\n","# trial_df.tail()\n","\n","idxx = trial_df[trial_df.iloc[:, 64] == 'Rest'].index\n","idxx2 = trial_df[trial_df.iloc[:, 64] == 'Feet'].index\n","# print(idxx,len(idxx))\n","# print(idxx2,len(idxx2))\n","\n","trial_df2 = trial_df.copy()\n","\n","\n","# sample_point = tasks_time[0]*SAMPLING_RATE\n","# if(trial_df2.iloc[sample_point+1,64] == class_x ):\n","#     temp_df = trial_df2.iloc[:sample_point,:]\n","#     next_task_idx = trial_df2[trial_df2.iloc[:, 64] == class_y].index\n","#     trial_df2.drop(trial_df2.index[0:next_task_idx[0]], inplace=True)\n","#     trial_df2.reset_index(drop=True, inplace=True)\n","#     new_df = pd.concat([new_df, temp_df], axis=0)\n","\n","# sample_point = tasks_time[1]*SAMPLING_RATE\n","# if(trial_df2.iloc[sample_point+1,64] == class_y ):\n","#     temp_df2 = trial_df2.iloc[:sample_point,:]\n","#     next_task_idx = trial_df2[trial_df2.iloc[:, 64] == class_x].index\n","#     trial_df2.drop(trial_df2.index[0:next_task_idx[0]], inplace=True)\n","#     trial_df2.reset_index(drop=True, inplace=True)    \n","\n","# new_df = pd.concat([temp_df, temp_df2], axis=0)\n","# new_df.reset_index(drop=True, inplace=True)\n","# new_df.tail()\n","\n","cleaned_df = data_cleaner(trial_df,CLASS_1,CLASS_2)\n","cleaned_df.head()\n","\n","data, labels = data_label_attacher(cleaned_df,CLASS_1,CLASS_2)\n","print(data.shape,labels.shape)\n","print(labels)\n","# for i in range(len(labels)):\n","#     if labels[i] == 1 :\n","#         print(\"hi\")\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-6007.68457</td>\n","      <td>12510.444336</td>\n","      <td>7844.45166</td>\n","      <td>-4246.978027</td>\n","      <td>-3228.525146</td>\n","      <td>-103.249702</td>\n","      <td>8590.283203</td>\n","      <td>-5608.668945</td>\n","      <td>15386.517578</td>\n","      <td>-11876.93457</td>\n","      <td>...</td>\n","      <td>-2211.25415</td>\n","      <td>-7136.249023</td>\n","      <td>43.948391</td>\n","      <td>7693.819824</td>\n","      <td>2708.186035</td>\n","      <td>-10187.832031</td>\n","      <td>10895.167969</td>\n","      <td>7435.178711</td>\n","      <td>15664.952148</td>\n","      <td>Begin_Feet</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-6012.343262</td>\n","      <td>12505.867188</td>\n","      <td>7834.443359</td>\n","      <td>-4234.376953</td>\n","      <td>-3221.28418</td>\n","      <td>-58.525509</td>\n","      <td>8586.755859</td>\n","      <td>-5612.939453</td>\n","      <td>15399.620117</td>\n","      <td>-11870.067383</td>\n","      <td>...</td>\n","      <td>-2209.654785</td>\n","      <td>-7135.818359</td>\n","      <td>42.244194</td>\n","      <td>7694.793945</td>\n","      <td>2700.129883</td>\n","      <td>-10194.820312</td>\n","      <td>10893.699219</td>\n","      <td>7429.57959</td>\n","      <td>15661.667969</td>\n","      <td>Feet</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-6004.281738</td>\n","      <td>12508.5</td>\n","      <td>7836.693359</td>\n","      <td>-4235.759766</td>\n","      <td>-3225.619385</td>\n","      <td>-89.742882</td>\n","      <td>8589.950195</td>\n","      <td>-5611.961426</td>\n","      <td>15399.019531</td>\n","      <td>-11871.919922</td>\n","      <td>...</td>\n","      <td>-2206.152344</td>\n","      <td>-7133.556641</td>\n","      <td>45.26141</td>\n","      <td>7695.370605</td>\n","      <td>2701.121582</td>\n","      <td>-10193.835938</td>\n","      <td>10892.120117</td>\n","      <td>7430.616699</td>\n","      <td>15662.744141</td>\n","      <td>Feet</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-6006.712891</td>\n","      <td>12511.026367</td>\n","      <td>7839.393555</td>\n","      <td>-4254.118164</td>\n","      <td>-3237.662842</td>\n","      <td>-97.241196</td>\n","      <td>8592.822266</td>\n","      <td>-5606.171387</td>\n","      <td>15382.796875</td>\n","      <td>-11880.046875</td>\n","      <td>...</td>\n","      <td>-2205.669434</td>\n","      <td>-7130.776367</td>\n","      <td>46.148624</td>\n","      <td>7693.93457</td>\n","      <td>2701.351074</td>\n","      <td>-10195.214844</td>\n","      <td>10894.549805</td>\n","      <td>7432.617188</td>\n","      <td>15667.950195</td>\n","      <td>Feet</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-6015.308594</td>\n","      <td>12510.445312</td>\n","      <td>7840.519043</td>\n","      <td>-4254.352539</td>\n","      <td>-3237.874268</td>\n","      <td>-128.30748</td>\n","      <td>8591.375</td>\n","      <td>-5594.76123</td>\n","      <td>15381.959961</td>\n","      <td>-11880.235352</td>\n","      <td>...</td>\n","      <td>-2208.33374</td>\n","      <td>-7131.682617</td>\n","      <td>45.585205</td>\n","      <td>7698.09082</td>\n","      <td>2702.700195</td>\n","      <td>-10194.633789</td>\n","      <td>10893.917969</td>\n","      <td>7433.499512</td>\n","      <td>15667.558594</td>\n","      <td>Feet</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>86272</th>\n","      <td>-7947.979492</td>\n","      <td>12310.938477</td>\n","      <td>7300.790527</td>\n","      <td>-4155.20166</td>\n","      <td>-3016.442627</td>\n","      <td>143.286392</td>\n","      <td>8194.839844</td>\n","      <td>-5476.609375</td>\n","      <td>14971.160156</td>\n","      <td>-11585.59082</td>\n","      <td>...</td>\n","      <td>-1267.154785</td>\n","      <td>-8254.25</td>\n","      <td>-468.513611</td>\n","      <td>7737.567383</td>\n","      <td>2609.070557</td>\n","      <td>-10310.354492</td>\n","      <td>11188.512695</td>\n","      <td>7139.75</td>\n","      <td>15612.225586</td>\n","      <td>Rest</td>\n","    </tr>\n","    <tr>\n","      <th>86273</th>\n","      <td>-7956.728516</td>\n","      <td>12311.724609</td>\n","      <td>7300.694336</td>\n","      <td>-4157.084473</td>\n","      <td>-3019.311035</td>\n","      <td>146.885925</td>\n","      <td>8196.986328</td>\n","      <td>-5477.582031</td>\n","      <td>14968.926758</td>\n","      <td>-11585.797852</td>\n","      <td>...</td>\n","      <td>-1267.393799</td>\n","      <td>-8251.016602</td>\n","      <td>-463.748169</td>\n","      <td>7735.005371</td>\n","      <td>2611.488525</td>\n","      <td>-10310.40625</td>\n","      <td>11187.453125</td>\n","      <td>7139.99707</td>\n","      <td>15614.25</td>\n","      <td>Rest</td>\n","    </tr>\n","    <tr>\n","      <th>86274</th>\n","      <td>-7955.460449</td>\n","      <td>12314.120117</td>\n","      <td>7301.058594</td>\n","      <td>-4155.061523</td>\n","      <td>-3020.093262</td>\n","      <td>138.646683</td>\n","      <td>8201.264648</td>\n","      <td>-5476.589355</td>\n","      <td>14971.043945</td>\n","      <td>-11588.185547</td>\n","      <td>...</td>\n","      <td>-1264.507202</td>\n","      <td>-8247.374023</td>\n","      <td>-463.993561</td>\n","      <td>7735.862793</td>\n","      <td>2611.591064</td>\n","      <td>-10316.472656</td>\n","      <td>11188.148438</td>\n","      <td>7143.306152</td>\n","      <td>15617.170898</td>\n","      <td>Rest</td>\n","    </tr>\n","    <tr>\n","      <th>86275</th>\n","      <td>-7945.963867</td>\n","      <td>12318.460938</td>\n","      <td>7304.883789</td>\n","      <td>-4156.449707</td>\n","      <td>-3019.900879</td>\n","      <td>141.031204</td>\n","      <td>8205.243164</td>\n","      <td>-5473.765137</td>\n","      <td>14969.541992</td>\n","      <td>-11589.478516</td>\n","      <td>...</td>\n","      <td>-1268.526611</td>\n","      <td>-8244.618164</td>\n","      <td>-459.132599</td>\n","      <td>7734.895508</td>\n","      <td>2614.547363</td>\n","      <td>-10317.243164</td>\n","      <td>11189.810547</td>\n","      <td>7147.561035</td>\n","      <td>15620.617188</td>\n","      <td>End_Hand</td>\n","    </tr>\n","    <tr>\n","      <th>86276</th>\n","      <td>-7882.408691</td>\n","      <td>12283.585938</td>\n","      <td>7250.119141</td>\n","      <td>-4124.23584</td>\n","      <td>-3024.423584</td>\n","      <td>136.330002</td>\n","      <td>8153.498047</td>\n","      <td>-5462.777344</td>\n","      <td>14983.795898</td>\n","      <td>-11505.228516</td>\n","      <td>...</td>\n","      <td>-1215.658203</td>\n","      <td>-8271.384766</td>\n","      <td>-516.570984</td>\n","      <td>7719.5625</td>\n","      <td>2577.339844</td>\n","      <td>-10267.151367</td>\n","      <td>11153.901367</td>\n","      <td>7142.475098</td>\n","      <td>15580.478516</td>\n","      <td>Begin_Tongue</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>86277 rows  65 columns</p>\n","</div>"],"text/plain":["                0             1            2            3            4   \\\n","0      -6007.68457  12510.444336   7844.45166 -4246.978027 -3228.525146   \n","1     -6012.343262  12505.867188  7834.443359 -4234.376953  -3221.28418   \n","2     -6004.281738       12508.5  7836.693359 -4235.759766 -3225.619385   \n","3     -6006.712891  12511.026367  7839.393555 -4254.118164 -3237.662842   \n","4     -6015.308594  12510.445312  7840.519043 -4254.352539 -3237.874268   \n","...            ...           ...          ...          ...          ...   \n","86272 -7947.979492  12310.938477  7300.790527  -4155.20166 -3016.442627   \n","86273 -7956.728516  12311.724609  7300.694336 -4157.084473 -3019.311035   \n","86274 -7955.460449  12314.120117  7301.058594 -4155.061523 -3020.093262   \n","86275 -7945.963867  12318.460938  7304.883789 -4156.449707 -3019.900879   \n","86276 -7882.408691  12283.585938  7250.119141  -4124.23584 -3024.423584   \n","\n","               5            6            7             8             9   ...  \\\n","0     -103.249702  8590.283203 -5608.668945  15386.517578  -11876.93457  ...   \n","1      -58.525509  8586.755859 -5612.939453  15399.620117 -11870.067383  ...   \n","2      -89.742882  8589.950195 -5611.961426  15399.019531 -11871.919922  ...   \n","3      -97.241196  8592.822266 -5606.171387  15382.796875 -11880.046875  ...   \n","4      -128.30748     8591.375  -5594.76123  15381.959961 -11880.235352  ...   \n","...           ...          ...          ...           ...           ...  ...   \n","86272  143.286392  8194.839844 -5476.609375  14971.160156  -11585.59082  ...   \n","86273  146.885925  8196.986328 -5477.582031  14968.926758 -11585.797852  ...   \n","86274  138.646683  8201.264648 -5476.589355  14971.043945 -11588.185547  ...   \n","86275  141.031204  8205.243164 -5473.765137  14969.541992 -11589.478516  ...   \n","86276  136.330002  8153.498047 -5462.777344  14983.795898 -11505.228516  ...   \n","\n","                55           56          57           58           59  \\\n","0      -2211.25415 -7136.249023   43.948391  7693.819824  2708.186035   \n","1     -2209.654785 -7135.818359   42.244194  7694.793945  2700.129883   \n","2     -2206.152344 -7133.556641    45.26141  7695.370605  2701.121582   \n","3     -2205.669434 -7130.776367   46.148624   7693.93457  2701.351074   \n","4      -2208.33374 -7131.682617   45.585205   7698.09082  2702.700195   \n","...            ...          ...         ...          ...          ...   \n","86272 -1267.154785     -8254.25 -468.513611  7737.567383  2609.070557   \n","86273 -1267.393799 -8251.016602 -463.748169  7735.005371  2611.488525   \n","86274 -1264.507202 -8247.374023 -463.993561  7735.862793  2611.591064   \n","86275 -1268.526611 -8244.618164 -459.132599  7734.895508  2614.547363   \n","86276 -1215.658203 -8271.384766 -516.570984    7719.5625  2577.339844   \n","\n","                 60            61           62            63            64  \n","0     -10187.832031  10895.167969  7435.178711  15664.952148    Begin_Feet  \n","1     -10194.820312  10893.699219   7429.57959  15661.667969          Feet  \n","2     -10193.835938  10892.120117  7430.616699  15662.744141          Feet  \n","3     -10195.214844  10894.549805  7432.617188  15667.950195          Feet  \n","4     -10194.633789  10893.917969  7433.499512  15667.558594          Feet  \n","...             ...           ...          ...           ...           ...  \n","86272 -10310.354492  11188.512695      7139.75  15612.225586          Rest  \n","86273  -10310.40625  11187.453125   7139.99707      15614.25          Rest  \n","86274 -10316.472656  11188.148438  7143.306152  15617.170898          Rest  \n","86275 -10317.243164  11189.810547  7147.561035  15620.617188      End_Hand  \n","86276 -10267.151367  11153.901367  7142.475098  15580.478516  Begin_Tongue  \n","\n","[86277 rows x 65 columns]"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["df.head(86277)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 5, 2, 6, 3, 7, 4, 8]\n"]}],"source":["a = [1, 2, 3, 4]\n","b = [5, 6, 7, 8]\n","\n","c = [item for pair in zip(a, b) for item in pair]\n","print(c)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Yes\n","Yes\n"]}],"source":["for i in range(9):\n","   task,rest = get_task_rest_times(i)\n","   task_list = []\n","   rest_list = [] \n","   for item in task:\n","    sumx = np.sum(item)\n","    task_list.append(sumx)\n","\n","   for item in rest:\n","    sumy = np.sum(item)\n","    rest_list.append(sumy)\n","\n","\n","all_equal_rest = all(element == 56 for element in rest_list)\n","all_equal_task = all(element == 56 for element in task_list)\n","\n","if all_equal_rest:\n","    print(\"Yes\") \n","if all_equal_task:\n","    print(\"Yes\")"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original array:\n","[[[0.37454012 0.95071431]\n","  [0.73199394 0.59865848]\n","  [0.15601864 0.15599452]]\n","\n"," [[0.05808361 0.86617615]\n","  [0.60111501 0.70807258]\n","  [0.02058449 0.96990985]]\n","\n"," [[0.83244264 0.21233911]\n","  [0.18182497 0.18340451]\n","  [0.30424224 0.52475643]]\n","\n"," [[0.43194502 0.29122914]\n","  [0.61185289 0.13949386]\n","  [0.29214465 0.36636184]]]\n","\n","Shuffled array along the first axis:\n","[[[0.83244264 0.21233911]\n","  [0.18182497 0.18340451]\n","  [0.30424224 0.52475643]]\n","\n"," [[0.37454012 0.95071431]\n","  [0.73199394 0.59865848]\n","  [0.15601864 0.15599452]]\n","\n"," [[0.43194502 0.29122914]\n","  [0.61185289 0.13949386]\n","  [0.29214465 0.36636184]]\n","\n"," [[0.05808361 0.86617615]\n","  [0.60111501 0.70807258]\n","  [0.02058449 0.96990985]]]\n"]}],"source":["seed_value = 42\n","np.random.seed(seed_value)\n","arr = np.random.rand(4, 3, 2)\n","\n","print(\"Original array:\")\n","print(arr)\n","\n","# Shuffle along the first axis\n","np.random.shuffle(arr)\n","\n","print(\"\\nShuffled array along the first axis:\")\n","print(arr)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    col1        col2 label\n","0      1        some     a\n","1      2      random     a\n","2      3        data     a\n","3      4         for     b\n","4      5     example     b\n","5      6    purposes     b\n","6      7          in     a\n","7      8        this     a\n","8      9        case     a\n","9     10          it     b\n","10    11        does     b\n","11    12  not matter     b\n","his\n","    col1        col2 label\n","0      1        some     a\n","1      2      random     a\n","2      3        data     a\n","3      7          in     a\n","4      8        this     a\n","5      9        case     a\n","6      4         for     b\n","7      5     example     b\n","8      6    purposes     b\n","9     10          it     b\n","10    11        does     b\n","11    12  not matter     b\n"]}],"source":["import pandas as pd\n","\n","# Assuming df is your DataFrame with the last column named 'label'\n","data = {'col1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n","        'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'case', 'it', 'does', 'not matter'],\n","        'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'a', 'b', 'b', 'b']}\n","\n","df = pd.DataFrame(data)\n","\n","print(df)\n","print(\"his\")\n","# Define a custom sorting order based on the desired grouping\n","sorting_order = {'a': 0, 'b': 1}\n","\n","# Create a new column with the sorting order\n","df['sorting_order'] = df.iloc[:, 2].map(sorting_order)\n","\n","# Sort the DataFrame based on the new column and the original order within each group\n","df.sort_values(by=['sorting_order', df.columns[2]], inplace=True)\n","\n","# Drop the temporary sorting column\n","df.drop('sorting_order', axis=1, inplace=True)\n","\n","# Optional: Reset the index if needed\n","df.reset_index(drop=True, inplace=True)\n","\n","# Display the sorted DataFrame\n","print(df)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[3, 3, 3, 4]\n"]}],"source":["data = {\n","    'col1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,13],\n","    'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'case', 'it', 'does', 'not matter','b'],\n","    'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'a', 'b', 'b', 'b','b']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","x=0\n","i=0\n","class_1 = 'a'\n","class_2 = 'b'\n","sampleList = []\n","while i<len(df):\n","    if (df.iloc[i,2]==class_1):\n","        x+=1\n","    else:\n","        i-=1\n","        sampleList.append(x)\n","        x=0\n","        class_1,class_2 = class_2,class_1\n","    i+=1\n","sampleList.append(x)\n","print(sampleList)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["group\n","2    3\n","4    4\n","dtype: int64\n","2\n","3\n","group\n","1    3\n","3    3\n","dtype: int64\n"]}],"source":["data = {\n","    'col1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,13],\n","    'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'case', 'it', 'does', 'not matter','c'],\n","    'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'a', 'b', 'b', 'b','b']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Identify consecutive groups of 'a's by creating a new group ID each time 'label' changes from 'b' to 'a'\n","df['group'] = (df['label'] != df['label'].shift(1)).cumsum()\n","\n","# Count occurrences of 'a' within each group\n","group_counts = df[df['label'] == 'a'].groupby('group').size()\n","\n","group_counts_b = df[df['label'] == 'b'].groupby('group').size()\n","print(group_counts_b)\n","print(group_counts_b.index[0])\n","print(group_counts_b.iloc[0])\n","print(group_counts)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["p_num = 4\n","b_num = 7\n","path = f'../../Participants/P{p_num}/'\n","mat = loadmat(path+'P'+str(p_num)+'B'+str(b_num)+'.mat', chars_as_strings=True, mat_dtype=True, squeeze_me=True, struct_as_record=False, verify_compressed_data_integrity=False, variable_names=None)\n","df_1 = pd.DataFrame(mat['Data'])\n"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hi\n","[6191, 10157, 8157, 4065, 10161, 8156, 4060, 6014]\n","[8156, 8156, 6178, 10157, 10156, 4064, 4063, 6015]\n","[10158, 6176, 8165, 10155, 4073, 8156, 6184, 4016]\n","[10165, 10155, 6183, 6177, 4060, 4062, 8162, 8016]\n"]}],"source":["extra_samples_block_counter(df_1,trial_order[0])"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hi\n","Tongue\n","[3096, 5078, 4079, 2032, 5081, 4078, 2030, 3007]\n","Feet\n","[4078, 4078, 3089, 5079, 5078, 2032, 2031, 3008]\n","Mis\n","[5079, 3088, 4082, 5078, 2036, 4078, 3092, 2008]\n","Hand\n","[5082, 5078, 3091, 3089, 2030, 2031, 4081, 4008]\n","hi\n","Feet\n","[3089, 4081, 2030, 3090, 5077, 2034, 4082, 5008]\n","Mis\n","[4080, 2030, 5078, 5078, 2036, 3088, 3089, 4007]\n","Hand\n","[2035, 5077, 5078, 4077, 4081, 2031, 3091, 3008]\n","Tongue\n","[2032, 3092, 3092, 4078, 5076, 5079, 4082, 2008]\n","hi\n","Hand\n","[4082, 2033, 2032, 5078, 3090, 4079, 5077, 3007]\n","Feet\n","[5078, 3088, 4078, 2030, 3091, 5082, 2032, 4007]\n","Tongue\n","[3085, 4079, 5076, 3094, 2029, 5078, 4078, 2007]\n","Mis\n","[2032, 2032, 3088, 3089, 4077, 5081, 5079, 4008]\n","hi\n","Tongue\n","[3089, 5077, 4077, 2032, 5077, 4079, 2031, 3008]\n","Mis\n","[4077, 4078, 3089, 5162, 5079, 2131, 2027, 3007]\n","Hand\n","[5109, 3095, 4111, 5081, 2063, 4081, 3135, 2006]\n","Feet\n","[5077, 5111, 3089, 3119, 2027, 2043, 4078, 4007]\n","hi\n","Mis\n","[4080, 2036, 2066, 3090, 5116, 4078, 3177, 5008]\n","Feet\n","[3130, 4082, 4088, 5132, 2029, 3144, 5079, 2007]\n","Hand\n","[5079, 3136, 2026, 4082, 3133, 2026, 4182, 5008]\n","Tongue\n","[2060, 5197, 5094, 2044, 3155, 3106, 4113, 4007]\n","hi\n","Feet\n","[4096, 3106, 3112, 2041, 2041, 4089, 5094, 5007]\n","Hand\n","[5089, 4087, 4091, 2045, 3106, 5092, 2060, 3007]\n","Tongue\n","[2043, 5086, 4088, 3101, 5085, 4171, 3176, 2007]\n","Mis\n","[3100, 2044, 2043, 4091, 4089, 3096, 5087, 5008]\n","hi\n","Hand\n","[4088, 4085, 2040, 2038, 4096, 3096, 5088, 5007]\n","Tongue\n","[5085, 3098, 2039, 5089, 4090, 2037, 3100, 4007]\n","Mis\n","[2029, 5084, 4038, 4084, 3099, 3093, 5084, 2007]\n","Feet\n","[4090, 2044, 5089, 4087, 3093, 5037, 2039, 3006]\n"]}],"source":["for b in range(7):\n","    extra_samples_block_counter(data_dict_3[b],trial_order[b],b)"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n","Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/xgboost-1.0.2+computecanada-py3-none-any.whl\n","Requirement already satisfied: numpy in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from xgboost) (1.24.2+computecanada)\n","Requirement already satisfied: scipy in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from xgboost) (1.10.1+computecanada)\n","Installing collected packages: xgboost\n","Successfully installed xgboost-1.0.2+computecanada\n"]}],"source":["! pip install xgboost"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n","Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/lightgbm-4.0.0+computecanada-py3-none-linux_x86_64.whl\n","Requirement already satisfied: numpy in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from lightgbm) (1.24.2+computecanada)\n","Requirement already satisfied: scipy in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from lightgbm) (1.10.1+computecanada)\n","Installing collected packages: lightgbm\n","Successfully installed lightgbm-4.0.0+computecanada\n"]}],"source":["! pip install lightgbm"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n","Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/catboost-1.0.6+computecanada-cp38-none-linux_x86_64.whl\n","Requirement already satisfied: matplotlib in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from catboost) (3.7.0+computecanada)\n","Requirement already satisfied: six in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from catboost) (1.16.0+computecanada)\n","Requirement already satisfied: scipy in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from catboost) (1.10.1+computecanada)\n","Requirement already satisfied: numpy>=1.16.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from catboost) (1.24.2+computecanada)\n","Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/plotly-5.18.0+computecanada-py3-none-any.whl\n","Requirement already satisfied: pandas>=0.24.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from catboost) (1.5.3+computecanada)\n","Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/graphviz-0.20.1+computecanada-py3-none-any.whl\n","Requirement already satisfied: pytz>=2020.1 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2023.3+computecanada)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2+computecanada)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (1.4.4+computecanada)\n","Requirement already satisfied: packaging>=20.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (23.1+computecanada)\n","Requirement already satisfied: cycler>=0.10 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (0.11.0+computecanada)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (6.0.0+computecanada)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (1.0.7+computecanada)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (3.1.1)\n","Requirement already satisfied: pillow>=6.2.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (9.5.0+computecanada)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from matplotlib->catboost) (4.41.1)\n","Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tenacity-8.2.3+computecanada-py3-none-any.whl\n","Requirement already satisfied: zipp>=3.1.0 in /home/mahdi146/jupyter2/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0+computecanada)\n","Installing collected packages: tenacity, graphviz, plotly, catboost\n","Successfully installed catboost-1.0.6+computecanada graphviz-0.20.1+computecanada plotly-5.18.0+computecanada tenacity-8.2.3+computecanada\n"]}],"source":["! pip install catboost"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMHUhd3A17lB+9o7HFw3Jl4","provenance":[]},"kernelspec":{"display_name":"kernel2","language":"python","name":"kernel2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
