{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696289517013,"user":{"displayName":"Mahdi Moeini","userId":"03671813669356560168"},"user_tz":-210},"id":"za0kvkt7u2Z5","outputId":"78ba6e7e-7a2c-4096-e595-beca84ab98ba"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mahdi146/jupyter2/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n","  from pandas import MultiIndex, Int64Index\n"]}],"source":["import sys\n","import mne\n","import scipy.io as sp\n","from scipy import interpolate\n","import numpy as np\n","import random\n","import pandas as pd\n","import multiprocessing as mp\n","import concurrent.futures\n","from mne.decoding import CSP\n","import pymrmr\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier as RF\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import logging\n","from scipy.io import loadmat\n","from scipy.signal import hamming\n","from scipy.signal import hann\n","from scipy.signal import blackman\n","from scipy.signal import kaiser\n","from scipy.signal import gaussian\n","from sklearn.decomposition import FastICA\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","# import lightgbm as lgb\n","# from catboost import CatBoostClassifier\n","# from sklearn.impute import KNNImputer\n","# from sklearn.decomposition import PCA\n","# from pyriemann.estimation import Covariances\n","# from pyriemann.tangentspace import TangentSpace\n","# from pyriemann.classification import MDM\n","from collections import Counter\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from scipy.signal import medfilt\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","\n","\n","# Set display options for NumPy\n","np.set_printoptions(threshold=np.inf)"]},{"cell_type":"markdown","metadata":{},"source":["# Initialization"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["WINDOW_TIME_LENGTH = 4\n","SAMPLING_RATE = 250\n","WINDOW_SAMPLE_LENGTH = WINDOW_TIME_LENGTH*SAMPLING_RATE\n","NUMBER_OF_CHANNELS = 64\n","beta = 1.5\n","\n","epoch_length = 1000\n","sampling_freq = 250\n","number_of_runs = 10\n","number_of_components = 10\n","number_of_selected_features = 10\n","number_of_processes = 10\n","number_of_bands = 9\n","column_names = ['participant', 'class1', 'class2','running_time','test_acc','train_acc','test_size','train_size','train_block','test_block']\n","column_names_v2 = ['participant', 'class1', 'class2','running_time','test_acc','train_acc','test_size','train_size','train_block','test_block','test_acc_vote']\n","\n","\n","trial_order=[['Tongue','Feet','Mis','Hand'],\n","            ['Feet','Mis','Hand','Tongue'],\n","            ['Hand','Feet','Tongue','Mis'],\n","            ['Tongue','Mis','Hand','Feet'],\n","            ['Mis','Feet','Hand','Tongue'],\n","            ['Feet','Hand','Tongue','Mis'],\n","            ['Hand','Tongue','Mis','Feet'],\n","            ['Tongue','Feet','Mis','Hand'],\n","            ['Mis','Tongue','Hand','Feet']]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Functions"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_task_rest_times(b_num):\n","    if b_num == 0:\n","        task_time = [[12, 16, 20, 8],\n","                    [16, 12, 20, 8],\n","                    [20, 16, 8, 12],\n","                    [20, 12, 8, 16]]\n","        \n","        rest_time = [[20, 8, 16, 12],\n","                    [16, 20, 8, 12],\n","                    [12, 20, 16, 8],\n","                    [20, 12, 8, 16]]\n","        \n","    elif b_num == 1:\n","        task_time = [[12, 8, 20, 16],\n","                    [16, 20, 8, 12],\n","                    [8, 20, 16, 12],\n","                    [8, 12, 20, 16]]\n","        \n","        rest_time = [[16, 12, 8, 20],\n","                    [8, 20, 12, 16],\n","                    [20, 16, 8, 12],\n","                    [12, 16, 20, 8]]\n","        \n","    elif b_num == 2:\n","        task_time = [[16, 8, 12, 20],\n","                    [20, 16, 12, 8],\n","                    [12, 20, 8, 16],\n","                    [8, 12, 16, 20]]\n","        \n","        rest_time = [[8, 20, 16, 12],\n","                    [12, 8, 20, 16],\n","                    [16, 12, 20, 8],\n","                    [8, 12, 20, 16]]\n","        \n","    elif b_num == 3:\n","        task_time = [[12, 16, 20, 8],\n","                    [16, 12, 20, 8],\n","                    [20, 16, 8, 12],\n","                    [20, 12, 8, 16]]\n","        \n","        rest_time = [[20, 8, 16, 12],\n","                    [16, 20, 8, 12],\n","                    [12, 20, 16, 8],\n","                    [20, 12, 8, 16]]\n","        \n","    elif b_num == 4:\n","        task_time = [[16, 8, 20, 12],\n","                    [12, 16, 8, 20],\n","                    [20, 8, 12, 16],\n","                    [8, 20, 12, 16]]\n","        \n","        rest_time = [[8, 12, 16, 20],\n","                    [16, 20, 12, 8],\n","                    [12, 16, 8, 20],\n","                    [20, 8, 12, 16]]\n","        \n","    elif b_num == 5:\n","        task_time = [[16, 12, 8, 20],\n","                    [20, 16, 12, 8],\n","                    [8, 16, 20, 12],\n","                    [12, 8, 16, 20]]\n","\n","        rest_time = [[12, 8, 16, 20],\n","                    [16, 8, 20, 12],\n","                    [20, 12, 16, 8],\n","                    [8, 16, 12, 20]]\n","        \n","    elif b_num == 6:\n","        task_time = [[16, 8, 12, 20],\n","                    [20, 8, 16, 12],\n","                    [8, 16, 12, 20],\n","                    [16, 20, 12, 8]]\n","\n","        rest_time = [[16, 8, 12, 20],\n","                    [12, 20, 8, 16],\n","                    [20, 16, 12, 8],\n","                    [8, 16, 20, 12]]     \n","    elif b_num ==7:\n","        task_time = [[12, 8, 20, 16],\n","                    [16, 20, 8, 12],\n","                    [8, 20, 16, 12],\n","                    [8, 12, 20, 16]]   \n","               \n","        rest_time = [[16, 12, 8, 20],\n","                    [8, 20, 12, 16],\n","                    [20, 16, 8, 12],\n","                    [12, 16, 20, 8]]  \n","    \n","    elif b_num == 8:\n","        task_time = [[16, 8, 12, 20],\n","                    [20, 16, 12, 8],\n","                    [12, 20, 8, 16],\n","                    [8, 12, 16, 20]]\n","        \n","        rest_time = [[8, 20, 16, 12],\n","                    [12, 8, 20, 16],\n","                    [16, 12, 20, 8],\n","                    [8, 12, 20, 16]]\n","        \n","    else:\n","        print(\"Error in block number\")\n","\n","    return task_time,rest_time\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def trial_times_genertor(task_times,rest_times):\n","    block_times = [item for pair in zip(task_times, rest_times) for item in pair]\n","    return block_times\n","    "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["\n","def fill_zeros_with_average(matrix):\n","    # Iterate through the matrix\n","    for i in range(matrix.shape[0]):\n","        for j in range(matrix.shape[1]):\n","            for k in range(matrix.shape[2]):\n","                if matrix[i, j, k] == 0:\n","                    # Find the neighboring non-zero elements\n","                    neighbors = []\n","                    if i > 0 and matrix[i - 1, j, k] != 0:\n","                        neighbors.append(matrix[i - 1, j, k])\n","                    if i < matrix.shape[0] - 1 and matrix[i + 1, j, k] != 0:\n","                        neighbors.append(matrix[i + 1, j, k])\n","                    if j > 0 and matrix[i, j - 1, k] != 0:\n","                        neighbors.append(matrix[i, j - 1, k])\n","                    if j < matrix.shape[1] - 1 and matrix[i, j + 1, k] != 0:\n","                        neighbors.append(matrix[i, j + 1, k])\n","                    if k > 0 and matrix[i, j, k - 1] != 0:\n","                        neighbors.append(matrix[i, j, k - 1])\n","                    if k < matrix.shape[2] - 1 and matrix[i, j, k + 1] != 0:\n","                        neighbors.append(matrix[i, j, k + 1])\n","\n","                    # Fill the zero with the average of neighboring non-zero values\n","                    if neighbors:\n","                        matrix[i, j, k] = sum(neighbors) / len(neighbors)\n","\n","    return matrix"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def calc_csp(x_train, y_train, x_test):\n","    # csp = CSP(n_components=number_of_components, reg='ledoit_wolf', log=True)\n","    csp = CSP(number_of_components)\n","\n","\n","\n","    \n","    # x_train = fill_zeros_with_average(x_train)\n","    # x_train = np.add(x_train, 0.000001)\n","\n","\n","\n","    nan_count = np.isnan(x_train).sum()\n","    print(\"Number of NaN values:\", nan_count)\n","\n","    empty_field_count = np.count_nonzero(x_train == 0)\n","    print(\"Number of empty fields:\", empty_field_count)\n","\n","    zeros_locations_3d = np.where(x_train == 0)\n","    # print(\"Locations of zeros:\", zeros_locations)\n","    \n","# Printing indices and corresponding values\n","    # for depth_idx, row_idx, col_idx in zip(zeros_locations_3d[0], zeros_locations_3d[1], zeros_locations_3d[2]):\n","    #     value_at_zero_location = x_train[depth_idx, row_idx, col_idx]\n","    #     print(f\"Zero found at position ({depth_idx}, {row_idx}, {col_idx}) with value {value_at_zero_location}\")\n","\n","\n","    csp_fit = csp.fit(x_train, y_train)\n","    train_feat = csp_fit.transform(x_train)\n","    test_feat = csp_fit.transform(x_test)\n","    return train_feat, test_feat"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def class_extractor(number_of_epochs, class_1, class_2, data, labels):\n","    size = sum(labels[:,0] == class_1) + sum(labels[:,0] == class_2)\n","    Final_labels = np.zeros((size,1)).astype(int)\n","    dataset = np.zeros((size,num_channels, epoch_length))\n","    index = 0\n","    for i in range(number_of_epochs):\n","        if labels[i,0] == class_1 or labels[i,0] == class_2:\n","            dataset[index,:,:] = data[i,:,:]\n","            Final_labels[index,0] = labels[i,0]\n","            index = index + 1\n","        else:\n","            continue\n","            \n","    return dataset, Final_labels"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def feature_extractor(dataset, labels, number_of_bands, test_data):\n","\n","    low_cutoff = 0\n","    \n","    for b in range(number_of_bands):\n","        logging.getLogger('mne').setLevel(logging.WARNING)\n","        low_cutoff += 4\n","        data = dataset.copy()\n","        data_test = test_data.copy() \n","\n","        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False, n_jobs = 4)\n","        filtered_data_test = mne.filter.filter_data(test_data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False, n_jobs = 4)\n","\n","        #PCA\n","        # from mne.decoding import UnsupervisedSpatialFilter\n","        # from sklearn.decomposition import PCA, FastICA\n","\n","        # pca = UnsupervisedSpatialFilter(PCA(64), average=False)\n","        # pca_fit = pca.fit(filtered_data)\n","        # filtered_data = pca_fit.transform(filtered_data)\n","        # filtered_data_test = pca_fit.transform(filtered_data_test)\n","        # train_feats = filtered_data\n","        # test_feats = filtered_data_test\n","\n","        # filtered_data = data\n","        # filtered_data_test = data_test\n","        \n","        [train_feats, test_feats] = calc_csp(filtered_data, labels[:,0], filtered_data_test)\n","        if b == 0:\n","            train_features = train_feats\n","            test_features = test_feats\n","        else:\n","            train_features = np.concatenate((train_features, train_feats), axis = 1)\n","            test_features = np.concatenate((test_features, test_feats), axis = 1)\n","    \n","    return train_features, test_features"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def feature_selector(train_features, labels, number_of_selected_features):\n","    X = pd.DataFrame(train_features)\n","    y = pd.DataFrame(labels)\n","    K = number_of_selected_features\n","    \n","    df = pd.concat([y,X], axis = 1)\n","    df.columns = df.columns.astype(str)\n","        \n","    selected_features = list(map(int, pymrmr.mRMR(df, 'MID', K)))\n","    return selected_features"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def data_reader(path,p_num,block_list):\n","    data_dict = {}\n","    for b_num in block_list:\n","        print(b_num)\n","        mat = loadmat(path+'P'+str(p_num)+'B'+str(b_num)+'.mat', chars_as_strings=True, mat_dtype=True, squeeze_me=True, struct_as_record=False, verify_compressed_data_integrity=False, variable_names=None)\n","        df = pd.DataFrame(mat['Data'])\n","        data_dict[b_num] = df\n","    return data_dict\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def get_group_start_indices(dataframe):\n","    group_indices = []\n","    current_label = None\n","\n","    for idx, row in dataframe.iterrows():\n","        if row.iloc[-1] != current_label:\n","            group_indices.append(idx)\n","            current_label = row.iloc[-1]\n","\n","    return group_indices"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def extra_samples_counter(df,class_1,class_2):\n","    x=0\n","    i=0\n","    sampleList = []\n","    while i<len(df):\n","        if (df.iloc[i,-1]==class_1):\n","            x+=1\n","        else:\n","            i-=1\n","            sampleList.append(x)\n","            x=0\n","            class_1,class_2 = class_2,class_1\n","        i+=1\n","    sampleList.append(x)\n","    print(sampleList)\n","    "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def extra_samples_block_counter(df,trial_order,b_num):\n","\n","    df.drop(df[df.iloc[:,-1].isin(['Begin', 'End'])].index, inplace=True)\n","    df.reset_index(drop=True, inplace=True)    \n","    df['group'] = (df.iloc[:,-1] != df.iloc[:,-1].shift(1)).cumsum()\n","\n","    \n","    group_counts_Rest = df[df.iloc[:,-1] == 'Rest'].groupby('group').size()\n","    with open('sampleList.txt', 'a') as file:\n","        file.write(f'block {b_num+1} '+'\\n')\n","        for j in range (len(trial_order)):\n","            print(trial_order[j])\n","            trial_num = j\n","            task_times,rest_times = get_task_rest_times(b_num)\n","            trial_times = trial_times_genertor(task_times[trial_num],rest_times[trial_num])\n","            trial_samples = [item*SAMPLING_RATE for item in trial_times]\n","            group_counts_task = df[df.iloc[:,-1] == trial_order[j]].groupby('group').size()\n","            sampleList = []\n","            for i in range(4):\n","                task = group_counts_task.iloc[i]\n","                rest = group_counts_Rest.iloc[4*j+i]\n","                sampleList.append(task)\n","                sampleList.append(rest)\n","            # extra_samples = [x-y for x,y in zip(sampleList,trial_samples)]\n","            file.write(', '.join(map(str, sampleList)) + f' trial={trial_order[j]} '+'\\n')\n","            print(sampleList)\n","        file.write('\\n\\n')\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def data_cleaner(df,class_1,class_2,tasks_time):\n","    # sys.exit() \n","    class_x = class_1\n","    class_y = class_2\n","    new_df = pd.DataFrame()\n","    trial_df = df.copy() \n","    print(tasks_time)\n","    for i in range(len(tasks_time)):\n","        sample_point = tasks_time[i]*SAMPLING_RATE\n","        if(trial_df.iloc[sample_point+1,-1] == class_x ):\n","            if(i==len(tasks_time)-1):\n","                temp_df = trial_df.iloc[:sample_point,:]\n","                new_df = pd.concat([new_df, temp_df], axis=0)\n","                new_df.reset_index(drop=True, inplace=True)\n","            else:    \n","                temp_df = trial_df.iloc[:sample_point,:]\n","                next_task_idx = trial_df[trial_df.iloc[:, -1] == class_y].index\n","                trial_df.drop(trial_df.index[0:next_task_idx[0]], inplace=True)\n","                trial_df.reset_index(drop=True, inplace=True)\n","                new_df = pd.concat([new_df, temp_df], axis=0)\n","                new_df.reset_index(drop=True, inplace=True)\n","                class_x,class_y = class_y,class_x\n","\n","    return new_df"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def class_seperator(cleaned_df,class_1,class_2):\n","    df = cleaned_df\n","    sorting_order = {class_1: 0, class_2: 1}\n","\n","    df['sorting_order'] = df.iloc[:, -1].map(sorting_order)\n","    df.sort_values(by=['sorting_order', df.columns[-1]], inplace=True)\n","    df.drop('sorting_order', axis=1, inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    return df"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def shuffler(dataset,labels):\n","    print(dataset.shape)\n","    print(labels.shape)\n","    np.random.seed(42)\n","    indices = np.random.permutation(len(dataset))\n","    shuffled_dataset = dataset[indices]\n","    shuffled_labels = labels[indices]\n","    return shuffled_dataset,shuffled_labels\n","    "]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def cal_epoch(df_len,sliding_len,window_len):\n","    print(window_len,sliding_len,df_len)\n","    number_of_epochs = int((int(df_len-window_len)/sliding_len)) +1\n","    return number_of_epochs"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def data_label_attacher(cleaned_df,class_1,class_2,random_flag,class_seperator_flag,sliding_time,number_of_channels):\n","    SLIDING_POINTS = int(sliding_time*SAMPLING_RATE)\n","    window_time = WINDOW_TIME_LENGTH\n","    new_df_ = cleaned_df.copy()\n","    new_df_.drop(cleaned_df.columns[-1], axis=1, inplace=True)\n","    X = new_df_.to_numpy()\n","    X = np.transpose(X)\n","    number_of_epochs = cal_epoch(int(int(len(cleaned_df)/SAMPLING_RATE)),sliding_time,window_time)\n","    print(number_of_epochs)\n","    dataset = np.zeros((number_of_epochs,number_of_channels,WINDOW_SAMPLE_LENGTH))\n","    labels = np.zeros((number_of_epochs,1)).astype(int)\n","\n","    index = get_group_start_indices(cleaned_df)\n","    index.append(len(cleaned_df))\n","    k = 0  \n","    startIdx = int(k * WINDOW_SAMPLE_LENGTH)\n","    endIdx = int((k+1) * WINDOW_SAMPLE_LENGTH )\n","    l = 0\n","    label = 1\n","    for i in range(number_of_epochs):\n","        \n","        if(startIdx>=index[l] and endIdx<=index[l+1]):\n","            print(startIdx,endIdx,index[l],index[l+1],\"start, end, index[l], index[l+1] in if\")\n","            slice_X = X[:, startIdx:endIdx]\n","\n","            kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","            slice_X *= kaiser_window\n","\n","            dataset[i, :, :] = slice_X\n","            labels[i,0] = label\n","            print(\"i is: \",i)\n","            print(\"label is: \",label)\n","\n","        else:\n","            \n","            temp = endIdx-index[l+1]\n","            print(temp,endIdx,index[l+1],\"temp,end,index l+1\")\n","            slice_X = X[:, startIdx:endIdx]\n","            kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","            slice_X *= kaiser_window\n","            dataset[i, :, :] = slice_X\n","\n","            if(temp<WINDOW_SAMPLE_LENGTH/2):\n","                print(\"i is: \",i)\n","                print(\"label is: \",label)\n","                labels[i,0] = label\n","            else:\n","                labels[i,0] = int(not(label))\n","                print(\"i is: \",i)\n","                print(\"label is: \",int(not(label)))\n","\n","            if(startIdx>=index[l+1]):\n","                l+=1\n","                print(f\"label changed in i = {i}\")\n","                label = int(not(label))\n","\n","                \n","\n","            \n","\n","        startIdx+=SLIDING_POINTS\n","        endIdx+=SLIDING_POINTS\n","    \n","\n","\n","\n","\n","\n","\n","\n","\n","        # a = df_len - wdinow_len\n","        # a/sliding_len\n","        # b = a%sliding_len\n","\n","\n","\n","\n","\n","####################################################\n","\n","\n","    # new_df_ = cleaned_df.copy()\n","    # new_df_.drop(cleaned_df.columns[-1], axis=1, inplace=True)\n","    # X = new_df_.to_numpy()\n","    # X = np.transpose(X)\n","    # number_of_epochs = int(len(new_df_)/WINDOW_SAMPLE_LENGTH)\n","    # number_of_epochs = int((int(len(new_df_))-WINDOW_SAMPLE_LENGTH)/SLIDING_POINTS) +1\n","\n","    \n","    # dataset = np.zeros((number_of_epochs,NUMBER_OF_CHANNELS,WINDOW_SAMPLE_LENGTH))\n","    # labels = np.zeros((number_of_epochs,1)).astype(int)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    \n","    # #Initialization\n","    # if class_seperator_flag:\n","    #     seperated_class_df = class_seperator(cleaned_df,class_1,class_2)\n","    #     new_df_ = seperated_class_df.copy()\n","    #     new_df_.drop(seperated_class_df.columns[-1], axis=1, inplace=True)\n","    #     X = new_df_.to_numpy()\n","    #     X = np.transpose(X)\n","    #     empty_field_count = np.count_nonzero(X == 0)\n","    #     print(\"Number of empty fields in X:\", empty_field_count)\n","    #     # zero_indices = np.where(X == 0)\n","    #     # print(\"befor filling\",len(zero_indices[0]))\n","    #     # X[zero_indices] += 0.001\n","    #     # zero_indices = np.where(X == 0)\n","    #     # print(\"after filling\",len(zero_indices[0]))\n","    #     number_of_epochs = int((int(len(new_df_))-WINDOW_SAMPLE_LENGTH)/TR_SLIDING_POINTS)\n","    #     print(number_of_epochs)\n","    # else :  \n","    #     new_df_ = cleaned_df.copy()\n","    #     new_df_.drop(cleaned_df.columns[-1], axis=1, inplace=True)\n","    #     X = new_df_.to_numpy()\n","    #     X = np.transpose(X)\n","    #     empty_field_count = np.count_nonzero(X == 0)\n","    #     print(\"Number of empty fields in X:\", empty_field_count)\n","    #     # zero_indices = np.where(X == 0)\n","    #     # print(\"befor filling\",len(zero_indices[0]))\n","    #     # X[zero_indices] += 0.001\n","    #     # zero_indices = np.where(X == 0)\n","    #     # print(\"after filling\",len(zero_indices[0]))\n","\n","    #     number_of_epochs = int(len(new_df_)/WINDOW_SAMPLE_LENGTH)\n","\n","    # dataset = np.zeros((number_of_epochs,NUMBER_OF_CHANNELS,WINDOW_SAMPLE_LENGTH))\n","    # labels = np.zeros((number_of_epochs,1)).astype(int)\n","\n","    # if class_seperator_flag:\n","    #     i = 0  \n","    #     startIdx = i * WINDOW_SAMPLE_LENGTH\n","    #     endIdx = (i+1) * WINDOW_SAMPLE_LENGTH \n","    #     while(endIdx<=int(len(new_df_))/2):\n","    #         slice_X = X[:, startIdx:endIdx]\n","\n","    #         kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","    #         slice_X *= kaiser_window\n","\n","    #         dataset[i, :, :] = slice_X\n","    #         labels[i,0] = 0\n","    #         # if (seperated_class_df.iloc[startIdx, 64] == class_1):\n","    #         #     labels[i,0] = 0\n","    #         # elif(seperated_class_df.iloc[startIdx, 64] == class_2):\n","    #         #     labels[i,0] = 1\n","    #         # else:\n","    #         #     labels[i,0] = 2\n","    #         startIdx+=TR_SLIDING_POINTS\n","    #         endIdx+=TR_SLIDING_POINTS\n","    #         i+=1\n","    #     # print(int(len(new_df_))/2,\"len\")    \n","    #     # print(endIdx,\"endIdx\")    \n","    #     # print(seperated_class_df.iloc[endIdx-2:endIdx+2,64])\n","       \n","    #     j = i\n","        \n","    #     startIdx = endIdx-TR_SLIDING_POINTS\n","    #     endIdx = startIdx+WINDOW_SAMPLE_LENGTH\n","    #     print(j, \"j is this\")\n","    #     while(endIdx<=int(len(new_df_))):\n","    #         slice_X = X[:, startIdx:endIdx]\n","\n","    #         kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","    #         slice_X *= kaiser_window\n","\n","    #         dataset[j, :, :] = slice_X\n","    #         labels[j,0] = 1\n","    #         # if (cleaned_df.iloc[startIdx, 64] == class_1):\n","    #         #     labels[j,0] = 0\n","    #         # elif(cleaned_df.iloc[startIdx, 64] == class_2):\n","    #         #     labels[j,0] = 1\n","    #         # else:\n","    #         #     labels[j,0] = 2\n","    #         startIdx+=TR_SLIDING_POINTS\n","    #         endIdx+=TR_SLIDING_POINTS\n","    #         j+=1\n","    #     print(j, \"j is this\")\n","    #     # dataset,labels = shuffler(dataset,labels)\n","\n","    # else:\n","    #     i = 0  \n","    #     start_idx = i * WINDOW_SAMPLE_LENGTH\n","    #     end_idx = (i+1) * WINDOW_SAMPLE_LENGTH \n","    #     while (end_idx<=int(len(new_df_))):\n","    #         slice_X = X[:, start_idx:end_idx]\n","\n","    #         kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,beta)\n","    #         slice_X *= kaiser_window\n","            \n","    #         dataset[i, :, :] = slice_X\n","    #         if (cleaned_df.iloc[start_idx, 64] == class_1):\n","    #             labels[i,0] = 0\n","    #         elif(cleaned_df.iloc[start_idx, 64] == class_2):\n","    #             labels[i,0] = 1\n","    #         else:\n","    #             labels[i,0] = 2\n","    #         start_idx+=SLIDING_POINTS\n","    #         end_idx+=SLIDING_POINTS\n","    #         i+=1\n","    #     # dataset,labels = shuffler(dataset,labels)\n","\n","\n","\n","#####################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    #For training and test purpose\n","    # if random_flag:\n","    #     randomlist = random.sample(range(number_of_epochs), number_of_epochs)\n","    # else:\n","    #     randomlist = list(range(number_of_epochs))\n","    #Labeling the data\n","\n","\n","\n","    # for i in range(number_of_epochs):\n","    #     start_idx = randomlist[i] * WINDOW_SAMPLE_LENGTH + SLIDING_POINTS\n","    #     end_idx = (randomlist[i] + 1) * WINDOW_SAMPLE_LENGTH\n","    #     slice_X = X[:, start_idx:end_idx]\n","\n","    #     # hamming_window = hamming(WINDOW_SAMPLE_LENGTH)\n","    #     # slice_X *= hamming_window\n","\n","    #     # hanning_window = hann(WINDOW_SAMPLE_LENGTH)\n","    #     # slice_X *= hanning_window\n","\n","    #     # blackman_window = blackman(WINDOW_SAMPLE_LENGTH)\n","    #     # slice_X *= blackman_window\n","\n","    #     # kaiser_window = kaiser(WINDOW_SAMPLE_LENGTH,0.5)\n","    #     # slice_X *= kaiser_window\n","\n","    #     # gaussian_window = gaussian(WINDOW_SAMPLE_LENGTH,0.5)\n","    #     # slice_X *= gaussian_window\n","\n","\n","    #     dataset[i, :, :] = slice_X\n","    #     if (cleaned_df.iloc[randomlist[i] * WINDOW_SAMPLE_LENGTH, 64] == class_1):\n","    #         labels[i,0] = 0\n","    #     elif(cleaned_df.iloc[randomlist[i] * WINDOW_SAMPLE_LENGTH, 64] == class_2):\n","    #         labels[i,0] = 1\n","    #     else:\n","    #         labels[i,0] = 2\n","    \n","    # empty_field_count = np.count_nonzero(dataset == 0)\n","    # print(\"Number of empty fields in dataset:\", empty_field_count,\"dataset shape\",dataset.shape)\n","    print(labels)\n","    return dataset,labels\n","\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def trial_cutter(data, class_1):\n","    df = data.copy()\n","    Begin_trigger = \"Begin\" + \"_\" + class_1\n","    End_trigger = \"End\" + \"_\" + class_1\n","    Begin_idx = df[df.iloc[:, -1] == Begin_trigger].index\n","    End_idx = df[df.iloc[:, -1] == End_trigger].index\n","    trial_df = df.iloc[Begin_idx[0]+1:End_idx[0],:]\n","    trial_df.reset_index(drop=True, inplace=True)\n","    trial_df.head()\n","    return trial_df"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def Begin_End_trigger_modifier(data):\n","    df = data.copy()\n","    Begin_indexes = df[df.iloc[:, -1] == 'Begin'].index\n","    End_indexes = df[df.iloc[:, -1] == 'End'].index\n","    if(len(Begin_indexes)==len(End_indexes)):\n","        for i in range(len(Begin_indexes)):\n","            index = Begin_indexes[i]+1\n","            val = df.iloc[index,-1]\n","            df.iloc[Begin_indexes[i],-1] = \"Begin\" + \"_\" + str(val)\n","            df.iloc[End_indexes[i],-1]   =  \"End\" + \"_\" + str(val)\n","    else:\n","        print(\"Trigger seinding Exception\")\n","    \n","    return df"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def preprocessor(data_,class_1,class_2,tasks_time,set_type,clean_flag,sliding_time,number_of_channels):\n","    CLASS_1 = class_1\n","    CLASS_2 = class_2\n","    df = data_.copy()\n","    modified_df = Begin_End_trigger_modifier(df)\n","    trial_df = trial_cutter(modified_df,CLASS_1)\n","    print(trial_df.shape,\"trial_df\")\n","    indexes = get_group_start_indices(trial_df)\n","    print(indexes,'tasks index starting point')\n","    if clean_flag:\n","        cleaned_df = data_cleaner(trial_df,CLASS_1,CLASS_2,tasks_time)\n","        final_df = cleaned_df.copy()\n","    else:\n","        final_df = trial_df.copy()\n","    print(final_df.shape,\"final_df\")\n","\n","    if set_type ==\"TRAIN\":\n","        random_flag = True\n","    elif set_type ==\"TEST\":\n","        random_flag = False\n","    else:\n","        print(\"Error in set type\")\n","\n","  \n","    final_data, final_labels = data_label_attacher(final_df,CLASS_1,CLASS_2,random_flag,clean_flag,sliding_time,number_of_channels)\n","      \n","    print(final_data.shape,\"final_data shape\")\n","    print(final_labels.shape,\"final_labels shape\")\n","    \n","    return final_data,final_labels"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def trials_set_builder(data_dict,blocks_set,set_label,class_1,class_2,clean_flag,sliding_time,channels_to_remove,number_of_channels):\n","    counter = 0\n","\n","    for b_num in blocks_set:\n","        trial_num = trial_order[b_num].index(class_1)\n","        task_times,rest_times = get_task_rest_times(b_num)\n","        print(task_times[trial_num],rest_times[trial_num])\n","        trial_times = trial_times_genertor(task_times[trial_num],rest_times[trial_num])\n","        print(trial_times)\n","        print(data_dict[b_num].shape,\"shape befor removal\")\n","        # data = remove_outliers_across_channels(data_dict[b_num],10)\n","        # data = remove_outliers(data_dict[b_num])\n","        data = data_dict[b_num]\n","        # data = apply_median_filter(data,9)\n","        if class_1== 'Tongue' or class_1 == 'Mis':\n","            data = channel_remover(data,channels_to_remove)\n","            number_of_channels =  NUMBER_OF_CHANNELS-len(channels_to_remove)\n","        else:\n","            number_of_channels = NUMBER_OF_CHANNELS\n","        print(number_of_channels,\"number_of_channels\")\n","        print(data.shape,\"shape after removal\")\n","        # sys.exit()\n","        df = data.copy()\n","        # last_column = df.pop(df.columns[-1])\n","        # df.drop(df.columns[-1], axis=1, inplace=True)\n","        # eeg_data = df.to_numpy().T  # Transpose to have channels in columns\n","\n","        # channel_names = [f'Ch{i+1}' for i in range(63)]\n","\n","        # # Create MNE-Python RawArray object\n","        # info = mne.create_info(ch_names=channel_names, sfreq=sampling_freq, ch_types='eeg')\n","        # raw = mne.io.RawArray(eeg_data, info)\n","\n","        # # Apply ICA\n","        # ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n","        # ica.fit(raw)\n","        # ica_components = ica.get_components()\n","\n","        # # Convert the ICA components to a DataFrame\n","        # df2 = pd.DataFrame(data=ica_components.T, columns=channel_names)\n","        # df2 = df2.assign(LastColumn=last_column)\n","        # # df = data.copy(deep=False)\n","        dataset,labels = preprocessor(df,class_1,class_2,trial_times,set_label,clean_flag,sliding_time,number_of_channels)\n","        # print(dataset.shape)\n","\n","        if counter == 0 :\n","            final_data = dataset\n","            final_labels = labels\n","            print(\"Before concatenation - final_data shape:\", final_data.shape, \"dataset shape:\", dataset.shape)\n","        else:\n","            final_data = np.vstack((final_data, dataset))\n","            final_labels = np.vstack((final_labels, labels))\n","            print(\"After concatenation - final_data shape:\", final_data.shape, \"final_labels shape:\", final_labels.shape)\n","\n","        counter+=1 \n","    # empty_field_count = np.count_nonzero(final_data == 0)\n","    # print(\"Number of empty fields in final_data:\", empty_field_count,\"final_data shape\",final_data.shape)\n","    return final_data,final_labels"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def find_duplicates(data_list):\n","    counted_values = Counter(data_list)\n","    duplicate_values = {value: count for value, count in counted_values.items() if count > 1}\n","    return duplicate_values"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def Statistical_analysor(p_num_list,data_dicts_list):\n","\n","    with open('/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Classification/Statistics.txt', 'w') as file:\n","        for p in range(len(p_num_list)):\n","            file.write(f'Particpant: {p+3} '+'\\n')\n","            for b in range(7):\n","                file.write(f'Block: {b+1} '+'\\n')\n","                data_pd = data_dicts_list[p][b]\n","                data = data_pd.iloc[:, :-1]\n","                data_np = data.values\n","                eeg_data = data_np\n","                print(\"Data type:\", type(eeg_data))\n","                print(\"Shape:\", eeg_data.shape)\n","                eeg_data = np.array(eeg_data)\n","                mean_values = np.mean(eeg_data, axis=0)\n","                variance_values = np.var(eeg_data, axis=0)\n","                std_deviation_values = []\n","                \n","                for i in range(num_channels):\n","                    print(f\"Channel {i + 1}:\")\n","                    print(f\"Mean: {mean_values[i]}\")\n","                    print(f\"Variance: {variance_values[i]}\")\n","                    std_deviation_values.append(np.sqrt(variance_values[i]))\n","                    print(f\"Standard Deviation: {std_deviation_values[i]}\")\n","                    print()\n","                    file.write(f'Channel {i+1}: '+'\\n')\n","                    file.write(f\"Mean: {mean_values[i]}\"+\"\\n\")\n","                    file.write(f\"Variance: {variance_values[i]}\"+\"\\n\")\n","                    file.write(f\"Standard Deviation: {std_deviation_values[i]}\"+\"\\n\\n\")\n","                \n","                lists_to_check = {\n","                'mean_values': mean_values,\n","                'variance_values': variance_values,\n","                'std_deviation_values': std_deviation_values\n","                }\n","                for list_name, data_list in lists_to_check.items():\n","                    duplicate_values = find_duplicates(data_list)\n","                    if duplicate_values:\n","                        print(f\"Duplicate values and their counts for {list_name}:\")\n","                        file.write(f\"Duplicate values and their counts for {list_name}:\"+\"\\n\")\n","                        for value, count in duplicate_values.items():\n","                            print(f\"Value: {value}, Count: {count}\")\n","                            file.write(f\"Value: {value}, Count: {count}\"+\"\\n\")\n","                    else:\n","                        print(f\"No duplicate values found in the {list_name} list.\")\n","                        file.write(f\"No duplicate values found in the {list_name} list.\"+\"\\n\")\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def custom_accuracy(y_true, y_pred):\n","    mismatches = []\n","    total = len(y_true)\n","    mismatch_count = 0\n","    \n","    for i, (true_label, pred_label) in enumerate(zip(y_true, y_pred)):\n","        if true_label != pred_label:\n","            mismatches.append(i)\n","            mismatch_count += 1\n","            \n","    accuracy = 1 - (mismatch_count / total)\n","    \n","    return accuracy, mismatch_count, mismatches"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def majority_vote_sliding_with_next(prediction_list, window_size=3):\n","    majority_votes = []\n","    \n","    for i in range(len(prediction_list) - window_size + 1):\n","        window = prediction_list[i:i+window_size]\n","        window_tuple = tuple(window)\n","        counts = Counter(window_tuple)\n","        majority = counts.most_common(1)[0][0]\n","        majority_votes.append(majority)\n","        \n","    return majority_votes\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def majority_vote_sliding_with_prev(prediction_list, window_size=3):\n","    majority_votes = []\n","    \n","    for i in range(len(prediction_list)):\n","        if i >= window_size - 1:\n","            start_index = i - window_size + 1\n","            window = prediction_list[start_index:i+1]\n","            counts = Counter(window)\n","            majority = counts.most_common(1)[0][0]\n","            majority_votes.append(majority)\n","        \n","    return majority_votes"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def majority_vote_sliding_with_prev_v2(prediction_list, window_size=3):\n","    majority_votes = []\n","    \n","    for i in range(len(prediction_list)):\n","        start_index = max(0, i - window_size + 1)\n","        window = prediction_list[start_index:i+1]\n","        counts = Counter(window)\n","        majority = counts.most_common(1)[0][0]\n","        majority_votes.append(majority)\n","        \n","    return majority_votes"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def channel_remover(df, channels):\n","    \n","    df_copy = df.copy()\n","    df_copy.drop(df.columns[channels], axis=1, inplace=True)\n","    return df_copy"]},{"cell_type":"markdown","metadata":{},"source":["# Reading Data"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reading P12\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n"]}],"source":["block_list = [0,1,2,3,4,5,6]\n","p_num_list = [12]\n","data_dicts_list = []\n","for p_num in p_num_list:\n","    print(f'reading P{p_num}')\n","    data_dict = data_reader(f'../../Participants/P{p_num}/', p_num, block_list)\n","    data_dicts_list.append(data_dict)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reading P3\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P4\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P5\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P6\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P7\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P8\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P9\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P10\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P11\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P12\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P13\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","reading P14\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n"]}],"source":["block_list = [0,1,2,3,4,5,6]\n","p_num_list = [3,4,5,6,7,8,9,10,11,12,13,14]\n","data_dicts_list = []\n","for p_num in p_num_list:\n","    print(f'reading P{p_num}')\n","    data_dict = data_reader(f'/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/Participants/P{p_num}/',p_num,block_list)\n","    data_dicts_list.append(data_dict)\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["def apply_pca(train_data, test_data=None, n_components=50):\n","    # Reshape train data\n","    train_data_reshaped = np.reshape(train_data, (train_data.shape[0], -1))\n","\n","\n","    scaler = StandardScaler()\n","    scaled_train_data = scaler.fit_transform(train_data_reshaped)\n","    # scaled_train_data = train_data_reshaped\n","    \n","    # Apply PCA on train data\n","    pca = PCA(n_components=n_components)\n","    pca.fit(scaled_train_data)\n","    transformed_train_data = pca.transform(scaled_train_data)\n","\n","    explained_variance_ratio = pca.explained_variance_ratio_\n","    cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n","    print(\"Explained Variance Ratio:\")\n","    print(explained_variance_ratio)\n","    print(\"\\nCumulative Explained Variance:\")\n","    print(cumulative_explained_variance)\n","\n","\n","    test_data_reshaped = np.reshape(test_data, (test_data.shape[0], -1))\n","    scaled_test_data = scaler.transform(test_data_reshaped)\n","    transformed_test_data = pca.transform(scaled_test_data)\n","\n","    return transformed_train_data, transformed_test_data\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(275, 50) (110, 50)\n"]}],"source":["tr_pca,te_pca = apply_pca(X_tr,X_te,50)\n","print(tr_pca.shape,te_pca.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Running Network"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[20, 16, 8, 12] [12, 20, 16, 8]\n","[20, 12, 16, 20, 8, 16, 12, 8]\n","(114042, 65) shape befor removal\n","64 number_of_channels\n","(114042, 65) shape after removal\n","(28543, 65) trial_df\n","[0, 5079, 8170, 12248, 17329, 19366, 23445, 26537] tasks index starting point\n","[20, 12, 16, 20, 8, 16, 12, 8]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 5000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 5000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","2000 3000 0 5000 start, end, index[l], index[l+1] in if\n","i is:  2\n","label is:  1\n","3000 4000 0 5000 start, end, index[l], index[l+1] in if\n","i is:  3\n","label is:  1\n","4000 5000 0 5000 start, end, index[l], index[l+1] in if\n","i is:  4\n","label is:  1\n","1000 6000 5000 temp,end,index l+1\n","i is:  5\n","label is:  0\n","label changed in i = 5\n","6000 7000 5000 8000 start, end, index[l], index[l+1] in if\n","i is:  6\n","label is:  0\n","7000 8000 5000 8000 start, end, index[l], index[l+1] in if\n","i is:  7\n","label is:  0\n","1000 9000 8000 temp,end,index l+1\n","i is:  8\n","label is:  1\n","label changed in i = 8\n","9000 10000 8000 12000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  1\n","10000 11000 8000 12000 start, end, index[l], index[l+1] in if\n","i is:  10\n","label is:  1\n","11000 12000 8000 12000 start, end, index[l], index[l+1] in if\n","i is:  11\n","label is:  1\n","1000 13000 12000 temp,end,index l+1\n","i is:  12\n","label is:  0\n","label changed in i = 12\n","13000 14000 12000 17000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  0\n","14000 15000 12000 17000 start, end, index[l], index[l+1] in if\n","i is:  14\n","label is:  0\n","15000 16000 12000 17000 start, end, index[l], index[l+1] in if\n","i is:  15\n","label is:  0\n","16000 17000 12000 17000 start, end, index[l], index[l+1] in if\n","i is:  16\n","label is:  0\n","1000 18000 17000 temp,end,index l+1\n","i is:  17\n","label is:  1\n","label changed in i = 17\n","18000 19000 17000 19000 start, end, index[l], index[l+1] in if\n","i is:  18\n","label is:  1\n","1000 20000 19000 temp,end,index l+1\n","i is:  19\n","label is:  0\n","label changed in i = 19\n","20000 21000 19000 23000 start, end, index[l], index[l+1] in if\n","i is:  20\n","label is:  0\n","21000 22000 19000 23000 start, end, index[l], index[l+1] in if\n","i is:  21\n","label is:  0\n","22000 23000 19000 23000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  0\n","1000 24000 23000 temp,end,index l+1\n","i is:  23\n","label is:  1\n","label changed in i = 23\n","24000 25000 23000 26000 start, end, index[l], index[l+1] in if\n","i is:  24\n","label is:  1\n","25000 26000 23000 26000 start, end, index[l], index[l+1] in if\n","i is:  25\n","label is:  1\n","1000 27000 26000 temp,end,index l+1\n","i is:  26\n","label is:  0\n","label changed in i = 26\n","27000 28000 26000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","Before concatenation - final_data shape: (28, 64, 1000) dataset shape: (28, 64, 1000)\n","[16, 20, 8, 12] [8, 20, 12, 16]\n","[16, 8, 20, 20, 8, 12, 12, 16]\n","(113991, 65) shape befor removal\n","64 number_of_channels\n","(113991, 65) shape after removal\n","(28488, 65) trial_df\n","[0, 4079, 6110, 11190, 16271, 18303, 21392, 24481] tasks index starting point\n","[16, 8, 20, 20, 8, 12, 12, 16]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","2000 3000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  2\n","label is:  1\n","3000 4000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  3\n","label is:  1\n","1000 5000 4000 temp,end,index l+1\n","i is:  4\n","label is:  0\n","label changed in i = 4\n","5000 6000 4000 6000 start, end, index[l], index[l+1] in if\n","i is:  5\n","label is:  0\n","1000 7000 6000 temp,end,index l+1\n","i is:  6\n","label is:  1\n","label changed in i = 6\n","7000 8000 6000 11000 start, end, index[l], index[l+1] in if\n","i is:  7\n","label is:  1\n","8000 9000 6000 11000 start, end, index[l], index[l+1] in if\n","i is:  8\n","label is:  1\n","9000 10000 6000 11000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  1\n","10000 11000 6000 11000 start, end, index[l], index[l+1] in if\n","i is:  10\n","label is:  1\n","1000 12000 11000 temp,end,index l+1\n","i is:  11\n","label is:  0\n","label changed in i = 11\n","12000 13000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  12\n","label is:  0\n","13000 14000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  0\n","14000 15000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  14\n","label is:  0\n","15000 16000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  15\n","label is:  0\n","1000 17000 16000 temp,end,index l+1\n","i is:  16\n","label is:  1\n","label changed in i = 16\n","17000 18000 16000 18000 start, end, index[l], index[l+1] in if\n","i is:  17\n","label is:  1\n","1000 19000 18000 temp,end,index l+1\n","i is:  18\n","label is:  0\n","label changed in i = 18\n","19000 20000 18000 21000 start, end, index[l], index[l+1] in if\n","i is:  19\n","label is:  0\n","20000 21000 18000 21000 start, end, index[l], index[l+1] in if\n","i is:  20\n","label is:  0\n","1000 22000 21000 temp,end,index l+1\n","i is:  21\n","label is:  1\n","label changed in i = 21\n","22000 23000 21000 24000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  1\n","23000 24000 21000 24000 start, end, index[l], index[l+1] in if\n","i is:  23\n","label is:  1\n","1000 25000 24000 temp,end,index l+1\n","i is:  24\n","label is:  0\n","label changed in i = 24\n","25000 26000 24000 28000 start, end, index[l], index[l+1] in if\n","i is:  25\n","label is:  0\n","26000 27000 24000 28000 start, end, index[l], index[l+1] in if\n","i is:  26\n","label is:  0\n","27000 28000 24000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (56, 64, 1000) final_labels shape: (56, 1)\n","[8, 12, 16, 20] [8, 12, 20, 16]\n","[8, 8, 12, 12, 16, 20, 20, 16]\n","(113935, 65) shape befor removal\n","64 number_of_channels\n","(113935, 65) shape after removal\n","(28430, 65) trial_df\n","[0, 2031, 4062, 7098, 10188, 14267, 19345, 24423] tasks index starting point\n","[8, 8, 12, 12, 16, 20, 20, 16]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 2000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 2000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","1000 3000 2000 temp,end,index l+1\n","i is:  2\n","label is:  0\n","label changed in i = 2\n","3000 4000 2000 4000 start, end, index[l], index[l+1] in if\n","i is:  3\n","label is:  0\n","1000 5000 4000 temp,end,index l+1\n","i is:  4\n","label is:  1\n","label changed in i = 4\n","5000 6000 4000 7000 start, end, index[l], index[l+1] in if\n","i is:  5\n","label is:  1\n","6000 7000 4000 7000 start, end, index[l], index[l+1] in if\n","i is:  6\n","label is:  1\n","1000 8000 7000 temp,end,index l+1\n","i is:  7\n","label is:  0\n","label changed in i = 7\n","8000 9000 7000 10000 start, end, index[l], index[l+1] in if\n","i is:  8\n","label is:  0\n","9000 10000 7000 10000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  0\n","1000 11000 10000 temp,end,index l+1\n","i is:  10\n","label is:  1\n","label changed in i = 10\n","11000 12000 10000 14000 start, end, index[l], index[l+1] in if\n","i is:  11\n","label is:  1\n","12000 13000 10000 14000 start, end, index[l], index[l+1] in if\n","i is:  12\n","label is:  1\n","13000 14000 10000 14000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  1\n","1000 15000 14000 temp,end,index l+1\n","i is:  14\n","label is:  0\n","label changed in i = 14\n","15000 16000 14000 19000 start, end, index[l], index[l+1] in if\n","i is:  15\n","label is:  0\n","16000 17000 14000 19000 start, end, index[l], index[l+1] in if\n","i is:  16\n","label is:  0\n","17000 18000 14000 19000 start, end, index[l], index[l+1] in if\n","i is:  17\n","label is:  0\n","18000 19000 14000 19000 start, end, index[l], index[l+1] in if\n","i is:  18\n","label is:  0\n","1000 20000 19000 temp,end,index l+1\n","i is:  19\n","label is:  1\n","label changed in i = 19\n","20000 21000 19000 24000 start, end, index[l], index[l+1] in if\n","i is:  20\n","label is:  1\n","21000 22000 19000 24000 start, end, index[l], index[l+1] in if\n","i is:  21\n","label is:  1\n","22000 23000 19000 24000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  1\n","23000 24000 19000 24000 start, end, index[l], index[l+1] in if\n","i is:  23\n","label is:  1\n","1000 25000 24000 temp,end,index l+1\n","i is:  24\n","label is:  0\n","label changed in i = 24\n","25000 26000 24000 28000 start, end, index[l], index[l+1] in if\n","i is:  25\n","label is:  0\n","26000 27000 24000 28000 start, end, index[l], index[l+1] in if\n","i is:  26\n","label is:  0\n","27000 28000 24000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (84, 64, 1000) final_labels shape: (84, 1)\n","[16, 12, 20, 8] [16, 20, 8, 12]\n","[16, 16, 12, 20, 20, 8, 8, 12]\n","(114428, 65) shape befor removal\n","64 number_of_channels\n","(114428, 65) shape after removal\n","(28726, 65) trial_df\n","[0, 4078, 8159, 11249, 16546, 21625, 23689, 25719] tasks index starting point\n","[16, 16, 12, 20, 20, 8, 8, 12]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","2000 3000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  2\n","label is:  1\n","3000 4000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  3\n","label is:  1\n","1000 5000 4000 temp,end,index l+1\n","i is:  4\n","label is:  0\n","label changed in i = 4\n","5000 6000 4000 8000 start, end, index[l], index[l+1] in if\n","i is:  5\n","label is:  0\n","6000 7000 4000 8000 start, end, index[l], index[l+1] in if\n","i is:  6\n","label is:  0\n","7000 8000 4000 8000 start, end, index[l], index[l+1] in if\n","i is:  7\n","label is:  0\n","1000 9000 8000 temp,end,index l+1\n","i is:  8\n","label is:  1\n","label changed in i = 8\n","9000 10000 8000 11000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  1\n","10000 11000 8000 11000 start, end, index[l], index[l+1] in if\n","i is:  10\n","label is:  1\n","1000 12000 11000 temp,end,index l+1\n","i is:  11\n","label is:  0\n","label changed in i = 11\n","12000 13000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  12\n","label is:  0\n","13000 14000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  0\n","14000 15000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  14\n","label is:  0\n","15000 16000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  15\n","label is:  0\n","1000 17000 16000 temp,end,index l+1\n","i is:  16\n","label is:  1\n","label changed in i = 16\n","17000 18000 16000 21000 start, end, index[l], index[l+1] in if\n","i is:  17\n","label is:  1\n","18000 19000 16000 21000 start, end, index[l], index[l+1] in if\n","i is:  18\n","label is:  1\n","19000 20000 16000 21000 start, end, index[l], index[l+1] in if\n","i is:  19\n","label is:  1\n","20000 21000 16000 21000 start, end, index[l], index[l+1] in if\n","i is:  20\n","label is:  1\n","1000 22000 21000 temp,end,index l+1\n","i is:  21\n","label is:  0\n","label changed in i = 21\n","22000 23000 21000 23000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  0\n","1000 24000 23000 temp,end,index l+1\n","i is:  23\n","label is:  1\n","label changed in i = 23\n","24000 25000 23000 25000 start, end, index[l], index[l+1] in if\n","i is:  24\n","label is:  1\n","1000 26000 25000 temp,end,index l+1\n","i is:  25\n","label is:  0\n","label changed in i = 25\n","26000 27000 25000 28000 start, end, index[l], index[l+1] in if\n","i is:  26\n","label is:  0\n","27000 28000 25000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (112, 64, 1000) final_labels shape: (112, 1)\n","[16, 8, 20, 12] [8, 12, 16, 20]\n","[16, 8, 8, 12, 20, 16, 12, 20]\n","(86447, 65) shape befor removal\n","64 number_of_channels\n","(86447, 65) shape after removal\n","(28936, 65) trial_df\n","[0, 4080, 6114, 8213, 11304, 16578, 20606, 23928] tasks index starting point\n","[16, 8, 8, 12, 20, 16, 12, 20]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","2000 3000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  2\n","label is:  1\n","3000 4000 0 4000 start, end, index[l], index[l+1] in if\n","i is:  3\n","label is:  1\n","1000 5000 4000 temp,end,index l+1\n","i is:  4\n","label is:  0\n","label changed in i = 4\n","5000 6000 4000 6000 start, end, index[l], index[l+1] in if\n","i is:  5\n","label is:  0\n","1000 7000 6000 temp,end,index l+1\n","i is:  6\n","label is:  1\n","label changed in i = 6\n","7000 8000 6000 8000 start, end, index[l], index[l+1] in if\n","i is:  7\n","label is:  1\n","1000 9000 8000 temp,end,index l+1\n","i is:  8\n","label is:  0\n","label changed in i = 8\n","9000 10000 8000 11000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  0\n","10000 11000 8000 11000 start, end, index[l], index[l+1] in if\n","i is:  10\n","label is:  0\n","1000 12000 11000 temp,end,index l+1\n","i is:  11\n","label is:  1\n","label changed in i = 11\n","12000 13000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  12\n","label is:  1\n","13000 14000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  1\n","14000 15000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  14\n","label is:  1\n","15000 16000 11000 16000 start, end, index[l], index[l+1] in if\n","i is:  15\n","label is:  1\n","1000 17000 16000 temp,end,index l+1\n","i is:  16\n","label is:  0\n","label changed in i = 16\n","17000 18000 16000 20000 start, end, index[l], index[l+1] in if\n","i is:  17\n","label is:  0\n","18000 19000 16000 20000 start, end, index[l], index[l+1] in if\n","i is:  18\n","label is:  0\n","19000 20000 16000 20000 start, end, index[l], index[l+1] in if\n","i is:  19\n","label is:  0\n","1000 21000 20000 temp,end,index l+1\n","i is:  20\n","label is:  1\n","label changed in i = 20\n","21000 22000 20000 23000 start, end, index[l], index[l+1] in if\n","i is:  21\n","label is:  1\n","22000 23000 20000 23000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  1\n","1000 24000 23000 temp,end,index l+1\n","i is:  23\n","label is:  0\n","label changed in i = 23\n","24000 25000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  24\n","label is:  0\n","25000 26000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  25\n","label is:  0\n","26000 27000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  26\n","label is:  0\n","27000 28000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (140, 64, 1000) final_labels shape: (140, 1)\n","[12, 8, 16, 20] [8, 16, 12, 20]\n","[12, 8, 8, 16, 16, 12, 20, 20]\n","(114266, 65) shape befor removal\n","64 number_of_channels\n","(114266, 65) shape after removal\n","(28530, 65) trial_df\n","[0, 3099, 5137, 7176, 11261, 15344, 18438, 23523] tasks index starting point\n","[12, 8, 8, 16, 16, 12, 20, 20]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 3000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 3000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","2000 3000 0 3000 start, end, index[l], index[l+1] in if\n","i is:  2\n","label is:  1\n","1000 4000 3000 temp,end,index l+1\n","i is:  3\n","label is:  0\n","label changed in i = 3\n","4000 5000 3000 5000 start, end, index[l], index[l+1] in if\n","i is:  4\n","label is:  0\n","1000 6000 5000 temp,end,index l+1\n","i is:  5\n","label is:  1\n","label changed in i = 5\n","6000 7000 5000 7000 start, end, index[l], index[l+1] in if\n","i is:  6\n","label is:  1\n","1000 8000 7000 temp,end,index l+1\n","i is:  7\n","label is:  0\n","label changed in i = 7\n","8000 9000 7000 11000 start, end, index[l], index[l+1] in if\n","i is:  8\n","label is:  0\n","9000 10000 7000 11000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  0\n","10000 11000 7000 11000 start, end, index[l], index[l+1] in if\n","i is:  10\n","label is:  0\n","1000 12000 11000 temp,end,index l+1\n","i is:  11\n","label is:  1\n","label changed in i = 11\n","12000 13000 11000 15000 start, end, index[l], index[l+1] in if\n","i is:  12\n","label is:  1\n","13000 14000 11000 15000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  1\n","14000 15000 11000 15000 start, end, index[l], index[l+1] in if\n","i is:  14\n","label is:  1\n","1000 16000 15000 temp,end,index l+1\n","i is:  15\n","label is:  0\n","label changed in i = 15\n","16000 17000 15000 18000 start, end, index[l], index[l+1] in if\n","i is:  16\n","label is:  0\n","17000 18000 15000 18000 start, end, index[l], index[l+1] in if\n","i is:  17\n","label is:  0\n","1000 19000 18000 temp,end,index l+1\n","i is:  18\n","label is:  1\n","label changed in i = 18\n","19000 20000 18000 23000 start, end, index[l], index[l+1] in if\n","i is:  19\n","label is:  1\n","20000 21000 18000 23000 start, end, index[l], index[l+1] in if\n","i is:  20\n","label is:  1\n","21000 22000 18000 23000 start, end, index[l], index[l+1] in if\n","i is:  21\n","label is:  1\n","22000 23000 18000 23000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  1\n","1000 24000 23000 temp,end,index l+1\n","i is:  23\n","label is:  0\n","label changed in i = 23\n","24000 25000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  24\n","label is:  0\n","25000 26000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  25\n","label is:  0\n","26000 27000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  26\n","label is:  0\n","27000 28000 23000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","Before concatenation - final_data shape: (28, 64, 1000) dataset shape: (28, 64, 1000)\n","[8, 16, 12, 20] [20, 16, 12, 8]\n","[8, 20, 16, 16, 12, 12, 20, 8]\n","(114207, 65) shape befor removal\n","64 number_of_channels\n","(114207, 65) shape after removal\n","(28575, 65) trial_df\n","[0, 2033, 7121, 11205, 15292, 18385, 21483, 26568] tasks index starting point\n","[8, 20, 16, 16, 12, 12, 20, 8]\n","(28000, 65) final_df\n","4 4 112\n","28\n","0 1000 0 2000 start, end, index[l], index[l+1] in if\n","i is:  0\n","label is:  1\n","1000 2000 0 2000 start, end, index[l], index[l+1] in if\n","i is:  1\n","label is:  1\n","1000 3000 2000 temp,end,index l+1\n","i is:  2\n","label is:  0\n","label changed in i = 2\n","3000 4000 2000 7000 start, end, index[l], index[l+1] in if\n","i is:  3\n","label is:  0\n","4000 5000 2000 7000 start, end, index[l], index[l+1] in if\n","i is:  4\n","label is:  0\n","5000 6000 2000 7000 start, end, index[l], index[l+1] in if\n","i is:  5\n","label is:  0\n","6000 7000 2000 7000 start, end, index[l], index[l+1] in if\n","i is:  6\n","label is:  0\n","1000 8000 7000 temp,end,index l+1\n","i is:  7\n","label is:  1\n","label changed in i = 7\n","8000 9000 7000 11000 start, end, index[l], index[l+1] in if\n","i is:  8\n","label is:  1\n","9000 10000 7000 11000 start, end, index[l], index[l+1] in if\n","i is:  9\n","label is:  1\n","10000 11000 7000 11000 start, end, index[l], index[l+1] in if\n","i is:  10\n","label is:  1\n","1000 12000 11000 temp,end,index l+1\n","i is:  11\n","label is:  0\n","label changed in i = 11\n","12000 13000 11000 15000 start, end, index[l], index[l+1] in if\n","i is:  12\n","label is:  0\n","13000 14000 11000 15000 start, end, index[l], index[l+1] in if\n","i is:  13\n","label is:  0\n","14000 15000 11000 15000 start, end, index[l], index[l+1] in if\n","i is:  14\n","label is:  0\n","1000 16000 15000 temp,end,index l+1\n","i is:  15\n","label is:  1\n","label changed in i = 15\n","16000 17000 15000 18000 start, end, index[l], index[l+1] in if\n","i is:  16\n","label is:  1\n","17000 18000 15000 18000 start, end, index[l], index[l+1] in if\n","i is:  17\n","label is:  1\n","1000 19000 18000 temp,end,index l+1\n","i is:  18\n","label is:  0\n","label changed in i = 18\n","19000 20000 18000 21000 start, end, index[l], index[l+1] in if\n","i is:  19\n","label is:  0\n","20000 21000 18000 21000 start, end, index[l], index[l+1] in if\n","i is:  20\n","label is:  0\n","1000 22000 21000 temp,end,index l+1\n","i is:  21\n","label is:  1\n","label changed in i = 21\n","22000 23000 21000 26000 start, end, index[l], index[l+1] in if\n","i is:  22\n","label is:  1\n","23000 24000 21000 26000 start, end, index[l], index[l+1] in if\n","i is:  23\n","label is:  1\n","24000 25000 21000 26000 start, end, index[l], index[l+1] in if\n","i is:  24\n","label is:  1\n","25000 26000 21000 26000 start, end, index[l], index[l+1] in if\n","i is:  25\n","label is:  1\n","1000 27000 26000 temp,end,index l+1\n","i is:  26\n","label is:  0\n","label changed in i = 26\n","27000 28000 26000 28000 start, end, index[l], index[l+1] in if\n","i is:  27\n","label is:  0\n","[[1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]]\n","(28, 64, 1000) final_data shape\n","(28, 1) final_labels shape\n","After concatenation - final_data shape: (56, 64, 1000) final_labels shape: (56, 1)\n","(140, 64, 1000) (140, 1) train shape\n","(56, 64, 1000) (56, 1) test shape\n","Number of NaN values: 0\n","Number of empty fields: 73\n","Number of NaN values: 0\n","Number of empty fields: 43\n","Number of NaN values: 0\n","Number of empty fields: 19\n","Number of NaN values: 0\n","Number of empty fields: 20\n","Number of NaN values: 0\n","Number of empty fields: 0\n","Number of NaN values: 0\n","Number of empty fields: 1\n","Number of NaN values: 0\n","Number of empty fields: 0\n","Number of NaN values: 0\n","Number of empty fields: 2\n","Number of NaN values: 0\n","Number of empty fields: 861\n","(140, 90) train_features shape\n","(56, 90) test_features shape\n","\n","\n"," *** This program and the respective minimum Redundancy Maximum Relevance (mRMR) \n","     algorithm were developed by Hanchuan Peng <hanchuan.peng@gmail.com>for\n","     the paper \n","     \"Feature selection based on mutual information: criteria of \n","      max-dependency, max-relevance, and min-redundancy,\"\n","      Hanchuan Peng, Fuhui Long, and Chris Ding, \n","      IEEE Transactions on Pattern Analysis and Machine Intelligence,\n","      Vol. 27, No. 8, pp.1226-1238, 2005.\n","\n","\n","*** MaxRel features ***\n","Order \t Fea \t Name \t Score\n","1 \t 12 \t 11 \t 0.359\n","2 \t 14 \t 13 \t 0.343\n","3 \t 4 \t 3 \t 0.278\n","4 \t 1 \t 0 \t 0.272\n","5 \t 11 \t 10 \t 0.262\n","6 \t 13 \t 12 \t 0.253\n","7 \t 5 \t 4 \t 0.220\n","8 \t 2 \t 1 \t 0.218\n","9 \t 27 \t 26 \t 0.209\n","10 \t 15 \t 14 \t 0.206\n","\n","*** mRMR features *** \n","Order \t Fea \t Name \t Score\n","1 \t 12 \t 11 \t 0.359\n","2 \t 27 \t 26 \t 0.126\n","3 \t 14 \t 13 \t 0.117\n","4 \t 23 \t 22 \t 0.087\n","5 \t 1 \t 0 \t 0.105\n","6 \t 5 \t 4 \t 0.097\n","7 \t 19 \t 18 \t 0.083\n","8 \t 37 \t 36 \t 0.084\n","9 \t 13 \t 12 \t 0.095\n","10 \t 4 \t 3 \t 0.092\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 1   Test_Predication: 1\n","Test_Real: 1   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 0\n","Test_Real: 0   Test_Predication: 1\n","Number of 0s: 70\n","Number of 1s: 70\n","selected_features:  [11, 26, 13, 22, 0, 4, 18, 36, 12, 3]\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 0   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 0\n","Test_Real_Vote: 1   Test_Predication_vote: 1\n","0.6785714285714286 18 [20, 21, 22, 23, 24, 25, 28, 32, 34, 35, 36, 40, 41, 43, 46, 51, 53, 54] acc, num_of_mismatches ,mismatches_list Mis\n","[1.0] train Mis\n","[0.7142857142857143] test Mis\n"]}],"source":["PATH = '/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Results/XGBoost/'\n","class_1_list = ['Hand','Feet','Tongue','Mis']\n","class_2 = 'Rest'\n","p_num_list = [12]\n","train_blocks_set = [0,1,2,3,4]\n","test_blocks_set = [5,6]\n","WINDOW_TIME_LENGTH = 4\n","sliding_time_tr = 4\n","sliding_time_te = 4\n","vote_window = 4\n","number_of_selected_features = 10\n","# channels_to_remove = [list(range(1,56))]\n","channels_to_remove = []\n","number_of_channels = NUMBER_OF_CHANNELS\n","params = {\n","    'max_depth': 5,\n","    'min_child_weight': 1,\n","    'gamma': 0,\n","    'subsample': 0.8,\n","    'colsample_bytree': 0.8,\n","    'learning_rate': 0.1,\n","}\n","\n","\n","p = 0\n","for p_num in p_num_list:\n","    import time\n","    start_time = time.time()\n","    for class_1 in class_1_list:\n","        X_tr, Y_tr = trials_set_builder(data_dicts_list[p],train_blocks_set,'TRAIN',class_1,class_2,True,sliding_time_tr,channels_to_remove,number_of_channels)\n","        X_te, Y_te = trials_set_builder(data_dicts_list[p],test_blocks_set,'TEST',class_1,class_2,True,sliding_time_te,channels_to_remove,number_of_channels)\n","\n","        print(X_tr.shape,Y_tr.shape,\"train shape\")\n","        print(X_te.shape,Y_te.shape,\"test shape\")\n","\n","        [train_features, test_features] = feature_extractor(X_tr, Y_tr, number_of_bands, X_te)\n","        # [train_features, test_features] =  apply_pca(X_tr,X_te,10)\n","        print(train_features.shape, \"train_features shape\")\n","        print(test_features.shape, \"test_features shape\")\n","        selected_features = feature_selector(train_features, Y_tr, number_of_selected_features)\n","\n","        train_acc_list = []\n","        test_acc_list = []\n","\n","        clf = XGBClassifier()\n","        for r in range(1):\n","            clf.fit(train_features[:, selected_features], Y_tr[:,0])\n","            \n","            y_pr_te = clf.predict(test_features[:, selected_features])\n","            y_pr_tr = clf.predict(train_features[:,selected_features])\n","\n","            accuracy_te = accuracy_score(Y_te, y_pr_te)\n","            test_acc_list.append(accuracy_te)\n","\n","            accuracy_tr = accuracy_score(Y_tr,y_pr_tr)\n","            train_acc_list.append(accuracy_tr)\n","\n","            # clf.fit(train_features[:, :], Y_tr[:,0])\n","\n","            # y_pr_te = clf.predict(test_features[:, :])\n","            # y_pr_tr = clf.predict(train_features[:,:])\n","\n","            # accuracy_te = accuracy_score(Y_te, y_pr_te)\n","            # test_acc_list.append(accuracy_te)\n","\n","            # accuracy_tr = accuracy_score(Y_tr,y_pr_tr)\n","            # train_acc_list.append(accuracy_tr)\n","\n","            \n","\n","\n","\n","\n","            for i in range(len(Y_te)):\n","                print(f\"Test_Real: {Y_te[i][0]}   Test_Predication: {y_pr_te[i]}\")\n","            \n","            count_0s = np.count_nonzero(Y_tr == 0)\n","            count_1s = np.count_nonzero(Y_tr == 1)\n","\n","            print(f\"Number of 0s: {count_0s}\")\n","            print(f\"Number of 1s: {count_1s}\")\n","\n","            print(\"selected_features: \",selected_features)\n","            # print(Y_te.shape,y_pr_te.shape,\"shape \")\n","            y_pr_te_Vote = majority_vote_sliding_with_prev_v2(y_pr_te,vote_window)\n","            Y_te_Vote = majority_vote_sliding_with_prev_v2(Y_te.reshape(-1),vote_window)\n","\n","            for i in range(len(Y_te)):\n","                print(f\"Test_Real_Vote: {Y_te_Vote[i]}   Test_Predication_vote: {y_pr_te_Vote[i]}\")\n","\n","\n","            acc, num_of_mismatches ,mismatches_list = custom_accuracy(Y_te_Vote,y_pr_te_Vote)\n","            print(acc,num_of_mismatches,mismatches_list, \"acc, num_of_mismatches ,mismatches_list\",class_1)\n","\n","\n","\n","\n","\n","        end_time = time.time()\n","        running_time = end_time-start_time\n","        participant = p_num\n","        class1 = class_1\n","        class2 = class_2\n","        running_time = running_time\n","        test_acc = np.average(test_acc_list)\n","        train_acc = np.average(train_acc_list)\n","        test_size = X_te.shape\n","        train_size = X_tr.shape\n","        train_block = '01234'\n","        test_block = '56'\n","        test_acc_vote = acc\n","\n","\n","\n","\n","\n","        new_row = [participant, class1, class2,running_time,test_acc,train_acc,test_size,train_size,train_block,test_block,test_acc_vote]\n","\n","        new_row_df = pd.DataFrame([new_row], columns=column_names_v2)\n","        rf = pd.read_csv(PATH +'P'+str(p_num)+'.csv')\n","        cf = pd.concat([rf, new_row_df], ignore_index=True)\n","        cf.to_csv(PATH +'P'+str(p_num)+'.csv',index=False)\n","\n","\n","\n","        print(train_acc_list,\"train\",class_1)\n","        print(test_acc_list,\"test\",class_1)\n","        \n","    p+=1\n","\n","        \n"]},{"cell_type":"markdown","metadata":{},"source":["# Side Analysis"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# #Frame Maker\n","PATH = '/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Results/XGBoost/Win4Shift2/'\n","df = pd.read_csv(PATH+'frame.csv')\n","p_num_list = [3,4,5,6,7,8,9,10,11,12,13,14]\n","for p_num in p_num_list:\n","    df.to_csv(PATH+'P'+str(p_num)+'.csv',index=False)\n","\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["\n","# # Specific path and file name\n","# file_path = '/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Results/XGBoost/frame.csv'  # Replace with your specific path\n","# df = pd.DataFrame(columns=column_names)\n","# # Write the DataFrame to a CSV file at the specified path\n","# df.to_csv(file_path, index=False)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["def remove_outliers(df):\n","    # Specify the threshold for outliers (you can adjust this based on your data)\n","    threshold = 10 ** 5\n","\n","    # Calculate median and MAD for each row\n","    median = df.iloc[:, :-1].median(axis=1)\n","    mad = np.median(np.abs(df.iloc[:, :-1].sub(median, axis=0)), axis=1)\n","    threshold_array = median + threshold * mad\n","\n","    # Identify rows with values exceeding the threshold\n","    outliers = df.iloc[:, :-1].gt(threshold_array[:, None], axis=0).any(axis=1)\n","\n","    # Remove rows identified as outliers\n","    clean_df = df[~outliers]\n","\n","    return clean_df\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from scipy import stats\n","\n","def remove_outliers_across_channels(df, threshold):\n","    # print(df.shape,\"shape0\")\n","\n","    data_columns = df.columns[:-1]  # Excluding the label column by default\n","\n","    # Separate the label column\n","    labels = df.iloc[:, -1]  # Assuming the label is in the last column\n","    data_without_label = df.iloc[:, :-1]  # DataFrame without the label column\n","\n","    # Calculate Z-scores for each row\n","    # print(data_without_label.shape,\"shape1\")\n","    # print(data_without_label[data_columns].shape,\"shape2\")\n","    # print(data_without_label.head(10))\n","    data_without_label[data_columns] = data_without_label[data_columns].apply(pd.to_numeric, errors='coerce')\n","    z_scores = stats.zscore(data_without_label[data_columns], axis=1)\n","    abs_z_scores = abs(z_scores)\n","\n","    filtered_entries = (abs_z_scores < threshold).all(axis=1)\n","    filtered_data = data_without_label[filtered_entries]\n","\n","    # Remove corresponding labels for removed rows\n","    filtered_labels = labels[filtered_entries]\n","\n","    # If you want to reset index after filtering\n","    filtered_data.reset_index(drop=True, inplace=True)\n","    filtered_labels.reset_index(drop=True, inplace=True)\n","\n","    # Combine the filtered data and labels\n","    filtered_df = pd.concat([filtered_data, filtered_labels], axis=1)\n","\n","    return filtered_df\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Majority Votes: [1, 1, 1, 0, 0, 1, 1, 0]\n","Majority Votes Previous: [1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n"]}],"source":["prediction_list = [1, 1, 1, 1, 0, 0, 1, 1, 0, 0]  # Replace with your actual prediction list\n","\n","result = majority_vote_sliding_with_next(prediction_list)\n","result2 = majority_vote_sliding_with_prev_v2(prediction_list)\n","print(\"Majority Votes:\", result)\n","print(\"Majority Votes Previous:\", result2)"]},{"cell_type":"markdown","metadata":{},"source":["## Getting Average"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3\n","4\n","5\n","6\n","7\n","9\n","10\n","11\n","13\n","14\n","[0.7518181818181817]\n","[0.7381818181818182]\n","[0.7018181818181818]\n","[0.6981818181818181]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>b1234_test</th>\n","      <th>b1234_test_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hand</td>\n","      <td>0.751818</td>\n","      <td>0.770000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Feet</td>\n","      <td>0.738182</td>\n","      <td>0.740909</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tongue</td>\n","      <td>0.701818</td>\n","      <td>0.699091</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mis</td>\n","      <td>0.698182</td>\n","      <td>0.700000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  b1234_test  b1234_test_vote\n","0    Hand    0.751818         0.770000\n","1    Feet    0.738182         0.740909\n","2  Tongue    0.701818         0.699091\n","3     Mis    0.698182         0.700000"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["PATH = '/home/mahdi146/projects/def-b09sdp/mahdi146/Cedar/Classification/EEG/Results/XGBoost/Win4Shift2/'\n","p_num_list = [3,4,5,6,7,9,10,11,13,14]\n","vf = pd.DataFrame(columns=column_names) \n","for p_num in p_num_list:\n","    print(p_num)\n","    rf = pd.read_csv(PATH + \"P\" + str(p_num) + \".csv\")\n","    vf = pd.concat([vf, rf], ignore_index=True)\n","vf.to_csv(PATH+ 'ResultsOfAllExcP8.csv', index=False)\n","# vf.tail()\n","    \n","columnNames = ['class','b1234_test','b1234_test_vote']\n","kf = pd.DataFrame(columns=columnNames)\n","kf.to_csv(PATH+'AverageAccExcP8.csv',index=False)\n","\n","vf = pd.read_csv(PATH +\"ResultsOfAllExcP8.csv\")\n","df = vf\n","\n","class_list=['Hand','Feet','Tongue','Mis']\n","blk_list = [1234]\n","for class_ in class_list:\n","    avg_list = []\n","    avg_vote_list = []\n","    for blk in blk_list:\n","        gf = df[(df['train_block'] == blk) & (df['class1'] == class_)]\n","        avg = gf['test_acc'].mean()\n","        avg_vote = gf['test_acc_vote'].mean()\n","        avg_list.append(avg)\n","        avg_vote_list.append(avg_vote)\n","    print(avg_list)    \n","    new_row = [class_, avg_list[0],avg_vote_list[0]] \n","    new_row_df = pd.DataFrame([new_row], columns=columnNames)\n","    rf = pd.read_csv(PATH + 'AverageAccExcP8.csv')\n","    cf = pd.concat([rf, new_row_df], ignore_index=True)\n","    cf.to_csv(PATH +'AverageAccExcP8.csv',index=False)  \n","kf = pd.read_csv(PATH +'AverageAccExcP8.csv') \n","kf.head()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    col1        col2 label\n","0      1        some     a\n","1      2      random     a\n","2      3        data     a\n","3      4         for     b\n","4      5     example     b\n","5      6    purposes     b\n","6      7          in     a\n","7      8        this     a\n","8      9        case     a\n","9     10          it     b\n","10    11        does     b\n","11    12  not matter     b\n","his\n","    col1        col2 label\n","0      1        some     a\n","1      2      random     a\n","2      3        data     a\n","3      7          in     a\n","4      8        this     a\n","5      9        case     a\n","6      4         for     b\n","7      5     example     b\n","8      6    purposes     b\n","9     10          it     b\n","10    11        does     b\n","11    12  not matter     b\n"]}],"source":["# Assuming df is your DataFrame with the last column named 'label'\n","data = {'col1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n","        'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'case', 'it', 'does', 'not matter'],\n","        'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'a', 'b', 'b', 'b']}\n","\n","df = pd.DataFrame(data)\n","\n","print(df)\n","print(\"his\")\n","# Define a custom sorting order based on the desired grouping\n","sorting_order = {'a': 0, 'b': 1}\n","\n","# Create a new column with the sorting order\n","df['sorting_order'] = df.iloc[:, 2].map(sorting_order)\n","\n","# Sort the DataFrame based on the new column and the original order within each group\n","df.sort_values(by=['sorting_order', df.columns[2]], inplace=True)\n","\n","# Drop the temporary sorting column\n","df.drop('sorting_order', axis=1, inplace=True)\n","\n","# Optional: Reset the index if needed\n","df.reset_index(drop=True, inplace=True)\n","\n","# Display the sorted DataFrame\n","print(df)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[3, 3, 3, 4]\n"]}],"source":["data = {\n","    'col1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,13],\n","    'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'case', 'it', 'does', 'not matter','b'],\n","    'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'a', 'b', 'b', 'b','b']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","x=0\n","i=0\n","class_1 = 'a'\n","class_2 = 'b'\n","sampleList = []\n","while i<len(df):\n","    if (df.iloc[i,2]==class_1):\n","        x+=1\n","    else:\n","        i-=1\n","        sampleList.append(x)\n","        x=0\n","        class_1,class_2 = class_2,class_1\n","    i+=1\n","sampleList.append(x)\n","print(sampleList)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 3, 6, 8]\n"]}],"source":["data = {\n","    'col1': [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12],\n","    'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'it', 'does', 'not matter'],\n","    'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'b', 'b', 'b']\n","}\n","df = pd.DataFrame(data)\n","\n","print(get_group_start_indices(df))\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["group\n","2    3\n","4    4\n","dtype: int64\n","2\n","3\n","group\n","1    3\n","3    3\n","dtype: int64\n"]}],"source":["data = {\n","    'col1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,13],\n","    'col2': ['some', 'random', 'data', 'for', 'example', 'purposes', 'in', 'this', 'case', 'it', 'does', 'not matter','c'],\n","    'label': ['a', 'a', 'a', 'b', 'b', 'b', 'a', 'a', 'a', 'b', 'b', 'b','b']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Identify consecutive groups of 'a's by creating a new group ID each time 'label' changes from 'b' to 'a'\n","df['group'] = (df['label'] != df['label'].shift(1)).cumsum()\n","\n","# Count occurrences of 'a' within each group\n","group_counts = df[df['label'] == 'a'].groupby('group').size()\n","\n","group_counts_b = df[df['label'] == 'b'].groupby('group').size()\n","print(group_counts_b)\n","print(group_counts_b.index[0])\n","print(group_counts_b.iloc[0])\n","print(group_counts)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../../Participants/P8v5/P8B7.mat'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Participants/P8v5/P8B7.mat'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m b_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Participants/P\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mv5/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp_num\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb_num\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchars_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_as_record\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_compressed_data_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Participants/P\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mv0/\u001b[39m\u001b[38;5;124m'\u001b[39m\n","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n","File \u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n","File \u001b[0;32m~/jupyter2/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Participants/P8v5/P8B7.mat'"]}],"source":["p_num = 8\n","b_num = 7\n","path = f'../../Participants/P{p_num}v5/'\n","mat = loadmat(path+'P'+str(p_num)+'B'+str(b_num)+'.mat', chars_as_strings=True, mat_dtype=True, squeeze_me=True, struct_as_record=False, verify_compressed_data_integrity=False, variable_names=None)\n","df = pd.DataFrame(mat['Data'])\n","\n","path = f'../../Participants/P{p_num}v0/'\n","mat = loadmat(path+'P'+str(p_num)+'B'+str(b_num)+'.mat', chars_as_strings=True, mat_dtype=True, squeeze_me=True, struct_as_record=False, verify_compressed_data_integrity=False, variable_names=None)\n","df_1 = pd.DataFrame(mat['Data'])\n","\n","print(df.shape)\n","print(df_1.shape)\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["from skimage.filters import median\n","\n","def apply_median_filter(df, window_size=10):\n","    channel_data = df.iloc[:, :-1].values\n","    labels = df.iloc[:, -1].values \n","    filtered_channel_data = np.zeros_like(channel_data) \n","\n","    for i in range(channel_data.shape[1]):\n","        print(i,\"channel\")\n","        filtered_channel_data[:, i] = median(channel_data[:, i], selem=np.ones(window_size))\n","\n","    df_filtered = pd.DataFrame(filtered_channel_data, columns=df.columns[:-1])\n","    df_filtered['Label'] = labels\n","    print(df_filtered.shape, \"shape after median filter\")\n","\n","    return df_filtered\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(114281, 65)\n","(114281, 65)\n"]}],"source":[]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hi\n","[6191, 10157, 8157, 4065, 10161, 8156, 4060, 6014]\n","[8156, 8156, 6178, 10157, 10156, 4064, 4063, 6015]\n","[10158, 6176, 8165, 10155, 4073, 8156, 6184, 4016]\n","[10165, 10155, 6183, 6177, 4060, 4062, 8162, 8016]\n"]}],"source":["extra_samples_block_counter(df_1,trial_order[0])"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hi\n","Tongue\n","[3093, 5078, 4078, 2030, 5078, 4079, 2032, 3007]\n","Feet\n","[4078, 4078, 3087, 5079, 5078, 2030, 2035, 3007]\n","Mis\n","[5080, 3089, 4076, 5079, 2036, 4077, 3093, 2007]\n","Hand\n","[5080, 5078, 3092, 3088, 2035, 2030, 4077, 4007]\n","hi\n","Feet\n","[3091, 4082, 2034, 3093, 5082, 2034, 4079, 5007]\n","Mis\n","[4083, 2033, 5079, 5082, 2031, 3090, 3087, 4007]\n","Hand\n","[2033, 5078, 5079, 4078, 4079, 2036, 3090, 3007]\n","Tongue\n","[2033, 3089, 3092, 4078, 5082, 5082, 4079, 2008]\n","hi\n","Hand\n","[4078, 2035, 2036, 5082, 3089, 4083, 5083, 3008]\n","Feet\n","[5077, 3088, 4078, 2035, 3088, 5077, 2033, 4007]\n","Tongue\n","[3088, 4082, 5082, 3087, 2031, 5079, 4077, 2007]\n","Mis\n","[2037, 2035, 3093, 3091, 4076, 5079, 5081, 4007]\n","hi\n","Tongue\n","[3087, 5081, 4082, 2035, 5077, 4077, 2031, 3008]\n","Mis\n","[4082, 4083, 3089, 5156, 5078, 2111, 2026, 3007]\n","Hand\n","[5105, 3088, 4106, 5077, 2065, 4076, 3122, 2007]\n","Feet\n","[5077, 5116, 3090, 3121, 2026, 2049, 4079, 4008]\n","hi\n","Mis\n","[4077, 2034, 2061, 3092, 5171, 4082, 3165, 5008]\n","Feet\n","[3201, 4078, 4077, 5177, 2030, 3166, 5083, 2007]\n","Hand\n","[5079, 3132, 2026, 4084, 3125, 2031, 4124, 5006]\n","Tongue\n","[2035, 5102, 5097, 2037, 3105, 3118, 4112, 4007]\n","hi\n","Feet\n","[4095, 3110, 3110, 2034, 2040, 4114, 5094, 5007]\n","Hand\n","[5089, 4087, 4090, 2039, 3101, 5087, 2047, 3008]\n","Tongue\n","[2029, 5086, 4086, 3095, 5085, 4088, 3106, 2008]\n","Mis\n","[3101, 2042, 2037, 4086, 4084, 3094, 5089, 5007]\n","hi\n","Hand\n","[4085, 4090, 2043, 2038, 3096, 3095, 5090, 5007]\n","Tongue\n","[5089, 3097, 2043, 5089, 4084, 2043, 3095, 4008]\n","Mis\n","[2030, 5086, 4100, 4086, 3100, 3095, 5090, 2008]\n","Feet\n","[4084, 2037, 5084, 4084, 3101, 5090, 2038, 3008]\n"]}],"source":["for b in range(7):\n","    extra_samples_block_counter(data_dicts_list[-1][b],trial_order[b],b)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMHUhd3A17lB+9o7HFw3Jl4","provenance":[]},"kernelspec":{"display_name":"jupyter2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
